[00:00:05] Hi listeners, welcome back to No Priors.
[00:00:08] Today I'm here with Mi Stendes, the
[00:00:10] co-founder and CEO of 11 Labs, which was
[00:00:13] founded to change the way we interact
[00:00:14] with each other [music] and with
[00:00:16] computers with voice. Over three short
[00:00:18] years, they've skyrocketed to [music]
[00:00:19] more than 300 million in run rate. Motti
[00:00:22] and I talk about the future of voice
[00:00:24] education, customer experience and the
[00:00:27] other applications of this voice as well
[00:00:30] as how to build a multi-segment [music]
[00:00:32] from self-s serve to enterprise and
[00:00:34] combined research and product company.
[00:00:35] Welcome Marty.
[00:00:37] >> S thanks for having me
[00:00:38] >> and thank you for doing this at 7 in the
[00:00:40] morning.
[00:00:40] >> Our pleasure. Thank you for doing that
[00:00:42] at 7:00 in the morning. It's great we we
[00:00:43] we got to finally do this together. Uh I
[00:00:46] think a lot of our listeners will have
[00:00:47] used or played with 11 at some point but
[00:00:49] for everybody else can you just
[00:00:50] reintroduce the company?
[00:00:52] >> Definitely we uh at 11 Labs we are
[00:00:54] solving how humans and technology
[00:00:56] interact how you can create seamlessly
[00:00:59] with that technology. Um what this means
[00:01:01] in practice is we build foundational
[00:01:04] audio models. So models in a space to
[00:01:06] help you create speech that sounds
[00:01:08] human, understand speech in a much
[00:01:10] better way or orchestrate all those
[00:01:12] components to make it interactive and
[00:01:14] then build products on top of that
[00:01:16] foundational models. And we have our
[00:01:18] creative product which is a platform for
[00:01:20] helping you with narrations for
[00:01:21] audiobooks with voiceovers for ads or
[00:01:23] movies or dabs of those movies to other
[00:01:25] languages. in our agent uh platform
[00:01:28] product which is effectively an offering
[00:01:30] to help you elevate customer experience
[00:01:32] built an agent for personal AI education
[00:01:35] new ways of immersive immersive media uh
[00:01:38] but all is kind of under under light of
[00:01:40] that mission of solving how we can
[00:01:42] interact with technology on our terms in
[00:01:44] a better way
[00:01:45] >> you started the company in 2022
[00:01:47] >> that's right
[00:01:48] >> and you've had amazing like rocket ship
[00:01:50] growth since then I'm sure it's felt up
[00:01:52] and down different ways I want to ask
[00:01:53] you about that can you give a sense of
[00:01:55] what the scale of the company is today.
[00:01:57] >> So we've grown to 350 people globally.
[00:02:01] We started from from Europe. We started
[00:02:03] as a remote company and are still first
[00:02:04] remote first but have hubs around the
[00:02:06] world with London being the biggest, New
[00:02:08] York being second biggest, Warso, San
[00:02:09] Francisco and now Tokyo and and one in
[00:02:12] Brazil. We are at uh 300 million in in
[00:02:15] in ARR which is uh roughly 50/50 between
[00:02:20] self-s serve so a lot of subscription
[00:02:22] and creators using our creative platform
[00:02:25] and then approaching 50 uh% on the
[00:02:27] enterprise side using our agents
[00:02:29] platform uh uh work and that's on the
[00:02:31] salesled classic salesled side and we
[00:02:34] serve more than 5 million monthly
[00:02:37] activives on that on that on that
[00:02:38] creative uh side of the work and then on
[00:02:41] the enterprise side we have few thousand
[00:02:42] customers from Fortune 500s to some of
[00:02:44] the fastest AI growing startups.
[00:02:46] >> I think this is such a you're an amazing
[00:02:48] founder, but I also think it's such an
[00:02:49] interesting company because it is um
[00:02:51] very unintuitive to I think many people
[00:02:54] and investors in particular. I don't
[00:02:57] know if you faced this at the beginning,
[00:02:58] but I we were both there in 2022.
[00:03:01] There's a there's a class of companies
[00:03:02] that allow creation in some way when we
[00:03:05] look at your like first business beyond
[00:03:07] the research itself. Uh, and I would put
[00:03:10] 11 and Midjourney and Sunno and Hunen in
[00:03:14] this category. And I think there's like
[00:03:15] this overall sense of like who really
[00:03:17] wants to do this? Um, what was your
[00:03:20] initial read of like how many people
[00:03:23] want to make voices or what made you
[00:03:25] believe that was going to be much
[00:03:26] broader than like if I look at dubbing
[00:03:29] for example like it's not a huge market.
[00:03:32] I think first piece was which is as you
[00:03:34] mentioned there's like a very
[00:03:35] >> it's very tricky to do both the product
[00:03:37] and the research. I'm in a in a lucky
[00:03:40] position that I that my co-ounder and I
[00:03:42] known each other for 15 years. I think
[00:03:43] he's the smartest person I know and has
[00:03:46] been able to create a lot of that
[00:03:47] research work to be able to create that
[00:03:49] foundation to then elevate that
[00:03:51] experience. But both of us are from from
[00:03:53] Poland originally and the original
[00:03:55] belief came from Poland. It's a it's a
[00:03:56] very peculiar thing. But if you if you
[00:03:58] watch a movie in Polish language, a
[00:04:00] foreign movie in Polish language, all
[00:04:02] the voices, whether it's a male voice or
[00:04:03] a female voice are narrated with one
[00:04:05] single character. So you have like a
[00:04:07] flat delivery for everything in a movie.
[00:04:09] >> A terrible experience.
[00:04:10] >> It is terrible experience and it's still
[00:04:12] you like if you grow up the the as soon
[00:04:15] as you learn English, you like switch
[00:04:16] out and you don't want to watch content
[00:04:18] in this way. Um and it's crazy that it
[00:04:20] still happens until today in this way
[00:04:22] for majority of of of content. combining
[00:04:25] that and I worked with Palunteer,
[00:04:27] Michael founder worked at Google, we
[00:04:29] knew that that will change in the future
[00:04:31] and that all the information will be
[00:04:33] available globally. And then as we
[00:04:35] started digging further, we realized
[00:04:36] >> in in every language in a high quality
[00:04:39] way. That was the starting point and the
[00:04:41] and the big the big thing was like
[00:04:43] instead of having it just translated um
[00:04:46] could you have the original voice,
[00:04:49] original emotions, original inonation
[00:04:51] carried across? Mhm.
[00:04:52] >> So like uh imagine having this podcast
[00:04:54] but say people could switch it over to
[00:04:57] Spanish and they still hear Sarah, they
[00:04:58] still hear Matty and and the same voice,
[00:05:00] the same the same delivery. Um which is
[00:05:03] kind of exactly what we did with Lex
[00:05:04] back when he interviewed Narendra Modi
[00:05:06] and you could like kind of immerse
[00:05:07] yourself in that story a lot better.
[00:05:09] Mhm.
[00:05:09] >> Um so that was the original uh uh kind
[00:05:12] of insight and um and we we then started
[00:05:15] digging further which is that just so
[00:05:17] much of the technology we interact with
[00:05:19] will will change whether this is how you
[00:05:22] create. It's still relatively tricky to
[00:05:25] bring voice alive. You you you you would
[00:05:27] you need to go through the expensive
[00:05:29] process of hiring a voice talent having
[00:05:31] a studio space having expensive tooling
[00:05:33] to then actually adjust it. The tooling
[00:05:35] isn't intuitive to be able to do this.
[00:05:37] So like all that creation process will
[00:05:40] and should change to make it easier for
[00:05:42] new people with keenness to bring that
[00:05:44] to life. Then a lot of the technology
[00:05:46] wasn't possible for you to be able to um
[00:05:49] recreate a specific voice or be able to
[00:05:51] create that in that high quality way.
[00:05:53] And then of course as we dived into
[00:05:55] further and and shifted away from the
[00:05:57] static piece, the whole interactive
[00:05:59] piece is still crazy in the way it
[00:06:01] functions where most of us seen this
[00:06:03] technological evolution over last over
[00:06:06] last decades. But you still will spend
[00:06:08] most of your time on the keyboard. You
[00:06:09] will look at the screen and and that
[00:06:12] interface feels broken. It should be
[00:06:14] where you can communicate with the
[00:06:16] devices through through speech through
[00:06:18] the most natural interface there is one
[00:06:21] that kind of started when the humanity
[00:06:23] humanity started and um and we realize
[00:06:25] we want to we want to solve that and I
[00:06:27] think now fast forward from 2022 I feel
[00:06:30] like many people will carry that belief
[00:06:31] too that voice is the interface of the
[00:06:33] future as you think about the devices
[00:06:35] around us whether it's smartphones whe
[00:06:37] it's computers whether it's robots
[00:06:39] speech will be one of the key ones but I
[00:06:40] think 2022 it wasn't and um and as If
[00:06:43] you think about the market for the
[00:06:44] creative side or whether for for that
[00:06:46] interactive side, it was like very clear
[00:06:49] it will be a huge a huge huge one.
[00:06:52] >> So even when you think about uh just the
[00:06:55] research part of your business and then
[00:06:57] you have products for at least two
[00:06:59] different markets and then you have this
[00:07:01] larger mission. A lot has changed in the
[00:07:02] last 5 or 10 years but it used to be
[00:07:04] like a very strongly held traditional
[00:07:07] belief of like one must do one thing
[00:07:09] well in a startup and there's no other
[00:07:11] path. like you're treating this like an
[00:07:13] interaction company, a platform company.
[00:07:14] How did you think about sequencing like
[00:07:17] the research and the product effort?
[00:07:19] >> Does that make sense? Or like thinking
[00:07:20] about new markets?
[00:07:21] >> And maybe wrapped up in that question
[00:07:23] too is just like well where are we in
[00:07:26] quality on on voice as well? Because if
[00:07:28] if I I would sort of claim like if the
[00:07:31] models are not good enough for certain
[00:07:33] use cases at all like it kind of doesn't
[00:07:35] make sense. Do product
[00:07:36] >> and I think that's right. It's it's
[00:07:38] almost exactly like when we when we
[00:07:39] started originally what we what we did
[00:07:41] was try to actually use existing models
[00:07:44] that were in the market and kind of
[00:07:45] optimize them for our first use case was
[00:07:48] actually starting with combination of of
[00:07:50] narration and dubbing and then on that
[00:07:52] creative side and um we realized pretty
[00:07:55] quickly that the models that existed
[00:07:57] just produced such a robotic and and and
[00:07:59] not not good speech that people didn't
[00:08:01] want to listen to it and that's where
[00:08:03] microfunders genius came in where he was
[00:08:05] able to assemble the team and and do a
[00:08:07] lot of the research himself to actually
[00:08:08] create new version of of creating that
[00:08:11] work. But like to your question, I think
[00:08:13] the the way we are kind of organized
[00:08:15] internally and how we think about
[00:08:16] sequencing a lot of that was looking at
[00:08:18] the first problem and then creating
[00:08:20] effectively a lab around that problem
[00:08:22] which is like a combination of mighty
[00:08:24] researchers, engineers, operators to go
[00:08:27] after that problem. And the first
[00:08:30] problem was the problem of voice. So how
[00:08:31] can we recreate the the voice and like
[00:08:34] you say it needs to have that research
[00:08:36] expertise to be able to do that well. So
[00:08:38] we started with effectively a voice lab
[00:08:40] which was that mission of can we narrate
[00:08:43] the work in in in in better way. It was
[00:08:45] a combination of roughly five people
[00:08:47] that were that were doing that work and
[00:08:49] then sequence the research first and
[00:08:51] then build a simple layer on top of that
[00:08:53] work to to allow people to use that work
[00:08:56] and then kind of expand it from there
[00:08:58] with a holistic suite for creating a
[00:09:00] full audiobook and then creating a full
[00:09:02] movie narration movie dab. Um and then
[00:09:05] we move to the next problem which is
[00:09:06] realization that okay we have solved the
[00:09:09] voice great for making content sound
[00:09:12] human
[00:09:12] >> the first problem for that to be useful
[00:09:15] for us to interact with the technology
[00:09:16] you need to solve how you bring the
[00:09:18] knowledge on demand into that. M
[00:09:20] >> so we effectively started then the
[00:09:21] second team which was a second lab uh an
[00:09:25] agent lab effectively which was a team
[00:09:27] that would combine researchers engineers
[00:09:29] and operators once more uh which would
[00:09:31] try to fix okay we have text to speech
[00:09:33] how do they now combine this with lambs
[00:09:36] and speechto text and orchestrate all
[00:09:38] those components together while
[00:09:39] integrating that with other systems to
[00:09:41] make it easier and then similarly you
[00:09:44] know you you you kind of expand from
[00:09:46] looking just at the voice layer into how
[00:09:48] those systems work together and here
[00:09:50] too. You need the research expertise to
[00:09:52] do that in a low latency way, efficient
[00:09:55] way, accurate way. Um, but at the same
[00:09:57] time, there's that product layer that
[00:09:59] starts forming that it's not only the
[00:10:00] orchestration that matters. It's also
[00:10:02] the integrations of how you link up to
[00:10:04] the legacy systems, how you build
[00:10:06] functions around it or how you deploy
[00:10:08] that in production and test, monitor,
[00:10:10] evaluate over time.
[00:10:11] >> Do you feel like you were creating new
[00:10:13] use cases when you built the tools? Do
[00:10:15] people know that they wanted to do this
[00:10:17] already? Um because one argument like
[00:10:20] that I remember hearing was like ah like
[00:10:23] you know enterprises don't know what to
[00:10:24] do with voice how many people really
[00:10:25] want to do it and then you're serving
[00:10:27] essentially like perhaps the like
[00:10:29] creator publisher side of your business.
[00:10:30] Yeah,
[00:10:31] >> it's definitely a combination of like
[00:10:33] initiatives that we believe will happen
[00:10:35] in the world and then like response to a
[00:10:36] lot of that like as I think back we you
[00:10:39] know of course voice the internal voice
[00:10:42] lab or agents lab then kind of that
[00:10:43] kickstarted so many of the other labs in
[00:10:46] response to the problems we started a
[00:10:48] music lab because people wanted to
[00:10:50] create music with 11 labs was a fully
[00:10:52] licensed model where people wanted to
[00:10:55] use and create speech but they wanted to
[00:10:57] add music in a in a simple way. We
[00:10:59] wanted to deliver that and then of
[00:11:01] course that kind of came together
[00:11:02] through how do we combine music, audio,
[00:11:05] sounds. Uh we are now integrating
[00:11:07] partner models from image and video into
[00:11:09] that suite is how could you combine all
[00:11:11] of that in in one and a lot of that was
[00:11:13] in response to the market saying like
[00:11:15] hey we would love this and then you will
[00:11:16] have completely different use cases even
[00:11:18] in that space. Let's say dabbing.
[00:11:20] Dubbing is a use case that we didn't
[00:11:22] feel there was like a a big push for for
[00:11:24] that but we we knew that in the ideal
[00:11:27] world in the future you will be able to
[00:11:29] have that content delivered naturally
[00:11:31] around the languages still carrying that
[00:11:34] um and I still think actually this
[00:11:35] market will be immense because it's not
[00:11:37] going to be only the static delivery in
[00:11:39] movies but if you travel around the
[00:11:42] world and want to communicate in real
[00:11:43] time like the full bubblefish idea from
[00:11:45] hitchhiker's guide of galaxy this will
[00:11:47] happen it will be like the biggest
[00:11:49] >> uh like the whole breaking down language
[00:11:51] barriers that are the barriers to
[00:11:53] communication to creation like all of
[00:11:55] that will break and and and that will be
[00:11:56] like the foundational real time dabbing
[00:11:59] concept. So super excited about that
[00:12:00] part. And similarly on on the on the
[00:12:02] agent side, you um you you you are like
[00:12:06] some obvious things that of course
[00:12:07] customers that we work with or partners
[00:12:09] will will want to want to integrate
[00:12:10] which is we want integrations with XYZ
[00:12:13] systems. But then there are like other
[00:12:15] parts that might not be as easy to
[00:12:17] predict of as you interact with
[00:12:19] technology you of course want to
[00:12:20] understand what's happening but you also
[00:12:22] want to understand how the things are
[00:12:24] being said and bring that into the fold
[00:12:26] which would be something we try to
[00:12:27] prioritize on our side. So then the
[00:12:28] people when they actually interact with
[00:12:30] the technology they realize oh express a
[00:12:32] thing is actually so so much more
[00:12:34] enjoyable and beneficial and helpful. So
[00:12:36] I want to ask a question about this
[00:12:37] which relates to quality. Um uh you
[00:12:40] [clears throat] know I work with a
[00:12:41] series of companies where we're
[00:12:44] >> selling a product to uh the buyers are
[00:12:46] generally not machine learning
[00:12:48] scientists. Right. Right.
[00:12:49] >> And even the the scientific community
[00:12:51] does not have the like full suite of
[00:12:53] eval benchmarks to understand every
[00:12:55] domain. Well there a well-known problem
[00:12:57] but I imagine for a lot of your
[00:12:59] customers it's not like they like know
[00:13:01] how to choose good voice. So how do you
[00:13:03] how do you deal with that problem? like
[00:13:04] is it like a hey I make a clone and like
[00:13:07] that sounds like me and I believe it I'm
[00:13:09] going to try all of these different
[00:13:11] options or or you know actually are you
[00:13:13] teaching people to do eval?
[00:13:15] >> It's a great question because I think
[00:13:17] there are like two big problems. One is
[00:13:19] like how do you benchmark the general
[00:13:21] space in audio where like you say it's
[00:13:23] like so dependent on the specific voice
[00:13:26] let alone like if you are training into
[00:13:28] interactive then it's like even more
[00:13:30] tricky. Um and then the second piece
[00:13:32] which is as you are working on specific
[00:13:34] use case how you select a voice. So I'll
[00:13:36] take the f second front first which is
[00:13:37] uh we have like a voice silier
[00:13:39] effectively with as we work with with
[00:13:42] enterprises we we we deploy that person
[00:13:45] to work with them and help them navigate
[00:13:47] that person is like a voice coach has an
[00:13:49] incredible voice themselves and uh and
[00:13:52] now we have like a team under that
[00:13:53] person that like will partner to help
[00:13:55] you find what's the right branding
[00:13:57] >> and now you have like the celebrity
[00:13:58] marketplace
[00:13:59] >> and now we have a celebrity marketplace
[00:14:01] to like help you even get iconic talent
[00:14:03] in there like sir Michael pain that
[00:14:06] piece was important because of course
[00:14:08] the voice will depend on the use case
[00:14:09] that you are trying to build the
[00:14:11] language all of that will will have an
[00:14:13] impact of what's the right voice for
[00:14:14] your customer base. So we have
[00:14:16] effectively a um a voice person helping
[00:14:20] those companies and some companies will
[00:14:21] be very opinionated on what they want.
[00:14:23] So they will sometimes select it
[00:14:25] themselves sometimes give us a brief of
[00:14:27] hey we want a voice that sounds
[00:14:28] professional neutral is coming. We
[00:14:31] recently had a company, one of the one
[00:14:33] of the biggest European companies that
[00:14:35] wanted uh that gave us a brief which is
[00:14:37] very original uh that uh they wanted as
[00:14:41] robotic voice as possible.
[00:14:42] >> Okay.
[00:14:42] >> It was counterintuitive.
[00:14:45] >> Um but for
[00:14:46] >> you like we can't do that anymore
[00:14:47] [laughter]
[00:14:48] >> almost. But we were like trying to go
[00:14:50] backwards of like how do we do that? But
[00:14:52] I think we we got a good result. Uh uh
[00:14:54] but recently we had a company in in
[00:14:57] Japan where um Japan and Korea where
[00:15:00] they wanted to serve different voices
[00:15:02] depending on the customer that's calling
[00:15:04] in. They have a
[00:15:05] >> older populationing and a very younger
[00:15:07] population. The younger one they wanted
[00:15:08] like one of the famous voices in the
[00:15:10] market that's very excitable and happy.
[00:15:12] Uh and for the older one they wanted
[00:15:13] like a calm slow speaking one. We help a
[00:15:15] lot with that. So that's on the voice
[00:15:17] piece and I do think it's going to be a
[00:15:19] a big important
[00:15:20] >> like a personalized choice and then it
[00:15:21] can even be dynamic in a customer.
[00:15:23] >> Yes. Okay. Exactly. Exactly. And then
[00:15:26] maybe in the future it's like going to
[00:15:27] be like fully depending on your
[00:15:29] interaction. You will like have a voice
[00:15:31] created as we understand the preferences
[00:15:34] of what people want. So you know like
[00:15:36] let's say you're in the evening and you
[00:15:37] are tired and you want a slightly
[00:15:39] different or maybe not. Maybe that's
[00:15:40] like the best uh focus time that you
[00:15:43] have like a voice that's that's giving
[00:15:44] that energy and probably it's a
[00:15:46] different when you wake up and gives you
[00:15:47] the morning news of what's happening or
[00:15:49] what's the weather. So like all of those
[00:15:51] could be different. Yesterday we had a
[00:15:54] we had a dinner with some of our our
[00:15:56] partners uh and one of them the first
[00:15:58] thing they said is like hey I have a new
[00:16:00] request for you. I want a New York voice
[00:16:02] with a Long Island voice uh uh accent
[00:16:04] which I never knew is a thing and it's
[00:16:06] territory is supposedly a thing. So uh
[00:16:08] so we have that and then on the first
[00:16:09] piece I don't I think it's unsolved
[00:16:11] problem still where I think you have a
[00:16:13] good benchmarks of course in LMS I think
[00:16:16] in image space they are pretty good in
[00:16:18] voice space you you have of course the
[00:16:20] speech quality but then so much of
[00:16:22] whether you like or not the speech
[00:16:24] depends on the voice that just if you
[00:16:27] compare a model A to model B and you
[00:16:30] serve them different voices even if the
[00:16:31] quality is very different the voice
[00:16:33] itself can just make that sort of
[00:16:35] different we've seen this I don't know
[00:16:37] if you know artificial analysis
[00:16:39] benchmarks. I think they're pretty good.
[00:16:41] Just switching the voice makes that
[00:16:42] makes such a such a big impact.
[00:16:43] >> That's so interesting. Yeah. And I
[00:16:45] wonder if um as you said this is uh the
[00:16:48] most dominant interaction mode we've had
[00:16:51] for millennia of all all of human
[00:16:53] history, right? And so
[00:16:54] >> and bias is of serving but I think so.
[00:16:56] >> We're just very sensitive to it. Um and
[00:16:58] I think people are going to be very
[00:16:59] sensitive to uh their their own
[00:17:02] personalization as well.
[00:17:03] >> 100%. I think there's also a third piece
[00:17:05] which maybe is not directly to your to
[00:17:07] your to your note but we've also
[00:17:09] realized that you have uh so you have
[00:17:11] the benchmarks you have like how do I
[00:17:13] find the right voice for my audience but
[00:17:14] even the understanding of how you
[00:17:16] describe audio data is still lagging in
[00:17:20] the industry like when we initially
[00:17:21] started we of course went into the
[00:17:23] traditional players for them to help us
[00:17:24] label not only what was said so like
[00:17:27] transcription but also how it was said
[00:17:29] like what are emotions use accent and
[00:17:31] most people just weren't able to do that
[00:17:33] workffect effectively because you kind
[00:17:35] of need to hear and have like a little
[00:17:38] bit of a skill set of like how would I
[00:17:40] describe this specific delivery. So we
[00:17:42] needed to create that ourselves. So I
[00:17:44] think there is that piece as well of
[00:17:46] like how do you effectively interpret
[00:17:48] the data of audio in a in a in a in a
[00:17:50] more qualitative basis. That's
[00:17:52] >> that's that's yeah trickier. Can you
[00:17:54] talk about what's happening on uh the
[00:17:57] agent platform side like what is
[00:18:00] challenging for you know businesses or
[00:18:02] even creators that are trying to build
[00:18:04] agents and what the what maybe what the
[00:18:06] surprising or high traction use cases
[00:18:07] are. I think everybody's kind of aware
[00:18:09] of the idea of like agent-based customer
[00:18:11] support but I imagine you're doing many
[00:18:13] things beyond that.
[00:18:14] >> Yeah. So the exactly customer support is
[00:18:16] probably the one that's like kicking off
[00:18:18] the quickest and and that's the the one
[00:18:20] that like we see overtaken so many use
[00:18:22] cases whether it's where I work with
[00:18:23] Cisco or Twilio or Tel Digital all of
[00:18:27] all of them are kind of elevating that
[00:18:28] to a high extent. I think the second
[00:18:31] exciting piece within that domain which
[00:18:33] is happening is the shift from
[00:18:35] effectively a reactive customer support.
[00:18:38] I have a problem. I'm reaching out the
[00:18:39] customer support into more of like a
[00:18:41] proactive
[00:18:43] >> part of the experience customer support.
[00:18:45] So to make it explicit, uh we work with
[00:18:48] the biggest e-commerce uh um shop in
[00:18:51] India, Misho, where they started working
[00:18:53] on the customer support side where I
[00:18:55] want the uh refund. I want to see the
[00:18:58] tracking of the the package to actually
[00:19:00] having an agent be a front part of the
[00:19:02] experience. So, if you go to the
[00:19:04] website, you can you have um you have
[00:19:06] the the widget, you can engage it
[00:19:07] through voice, and you can ask it, hey,
[00:19:09] can you help me navigate to item X, item
[00:19:12] uh Y, or can you explain what's the
[00:19:14] right thing for me to give up for a gift
[00:19:16] for this period of time? And then it
[00:19:18] will actually help you based on your
[00:19:20] questions, based on what is on the
[00:19:22] offer, show you those items, navigate to
[00:19:24] the right parts of the piece, maybe go
[00:19:26] all the way through the checkout. And I
[00:19:27] think this will be a phenomenal thing of
[00:19:28] like elevating the full experience where
[00:19:30] that's more of an assistant across the
[00:19:32] whole thing. We kicked off our work with
[00:19:34] Square that enable sort of businesses to
[00:19:36] do that work. Exactly the same pattern
[00:19:38] started with voice ordering. Uh how can
[00:19:40] now this be part of the full discovery
[00:19:42] experience too where you get items shown
[00:19:44] to you. You can have a lot more
[00:19:46] explanation which I think will be a
[00:19:47] phenomenal piece where where effectively
[00:19:50] from the beginning to the end. So that's
[00:19:52] one category. The second one is the
[00:19:54] wider shift from static to immersive
[00:19:57] media where there's just so much
[00:19:59] incredible stories and IP that today
[00:20:01] exist in effectively one way of delivery
[00:20:04] and now you'll be able to interact with
[00:20:07] that content in a completely new way. We
[00:20:10] uh I think one of the incredible use
[00:20:11] cases was working with Epic Games. We
[00:20:14] worked with them on bringing the voice
[00:20:15] of Darth Vader and Darth Vader into
[00:20:18] Fortnite where millions of players could
[00:20:20] interact with Darth Vader life in the
[00:20:22] game where you had like a full
[00:20:25] experience of of Darth Vader in a in a
[00:20:27] in in a new way. And I think this will
[00:20:29] be a theme across whether it's talking
[00:20:32] to a book, talking to the character that
[00:20:34] you like to the whole the whole space
[00:20:37] shifting. And then I think the one
[00:20:38] that's that I'm most excited about for
[00:20:42] the world and for the shift is going to
[00:20:43] be education where you will just be able
[00:20:46] to have like effectively a personal
[00:20:49] tutor uh on your headphone and you like
[00:20:52] actually study something in a in a in an
[00:20:54] amazing way. I'll give you like two
[00:20:56] quick examples. One is uh we recently
[00:20:58] worked uh with chess.com. I'm a I'm a
[00:21:01] huge fan of chess. I'm a true chess fan.
[00:21:03] Okay, great. So you can learn chess but
[00:21:06] you can have Hikaru Nakamura or Magnus
[00:21:08] Carlson be your your teacher of how you
[00:21:10] deliver that which is amazing or even
[00:21:14] Botus sisters or it's like all all the
[00:21:16] plethora of different players that
[00:21:17] engaged with that which I think is great
[00:21:19] and then maybe a last one which is a
[00:21:21] master class who we worked with to shift
[00:21:24] from you can of course have the content
[00:21:26] go through step by step
[00:21:28] >> um but you can also have like an
[00:21:30] interactive experience and the best
[00:21:31] example of that was working with Chris
[00:21:33] Boss
[00:21:34] the FBI negotiator, one of the top
[00:21:36] negotiators who has a masterclass
[00:21:38] lesson, but then you can actually call
[00:21:39] him and have a practice negotiation,
[00:21:41] which is crazy.
[00:21:42] >> Yeah. Got to get that hostage out. We'll
[00:21:44] definitely try it.
[00:21:45] >> Yeah. Um
[00:21:46] >> can I add one more? I think the one one
[00:21:48] last one which combines all of them
[00:21:50] together which I which I realized just
[00:21:51] recently is uh which was crazy. So
[00:21:54] recently I went to uh to Ukraine where
[00:21:57] we are working with ministry of
[00:21:58] transformation where they are
[00:22:00] effectively creating a first agent
[00:22:02] government.
[00:22:03] >> And the crazy thing is they have all of
[00:22:05] those
[00:22:06] >> government
[00:22:06] >> agentic government. So they want to like
[00:22:09] rechange of how they run all the
[00:22:11] ministries.
[00:22:12] >> Okay.
[00:22:12] >> And it sounds
[00:22:15] like a big ambitious goal and lofty.
[00:22:17] >> No, I think the baseline is like here.
[00:22:18] So actually I'm I'm by that immediately.
[00:22:20] Yeah. And the crazy thing is I think
[00:22:23] they are like so ahead in actually doing
[00:22:25] that
[00:22:25] >> and I think they are like uh uh two
[00:22:28] concrete things there. One they they
[00:22:30] kind of combine all those use cases. So
[00:22:31] they we we are looking into how they can
[00:22:34] have effectively customer support of
[00:22:36] government whether it's asking about
[00:22:37] benefits or employment about process of
[00:22:40] of how you leave uh the country. All of
[00:22:42] that be run through effectively a
[00:22:45] digital app. Then two how you can have
[00:22:46] proactive way of informing citizens of
[00:22:48] things that might be happening. but then
[00:22:50] having education system that also run
[00:22:52] through like this personal uh uh
[00:22:54] tutoring experience and all of that is
[00:22:56] happening. So that was that was
[00:22:57] incredible to see and the second amazing
[00:22:59] thing was that the way they've done it.
[00:23:00] So they have the digital transformation
[00:23:02] piece but they have engineering leaders
[00:23:04] in each of the ministries that lead
[00:23:06] those efforts and then bring them back
[00:23:08] to that one central piece. So that is
[00:23:10] like incredible to see and and and also
[00:23:12] proud to be able to be working with with
[00:23:14] them on on that shift. that despite
[00:23:16] everything that's happening they're like
[00:23:18] so
[00:23:19] >> that's amazing that's really encouraging
[00:23:21] um can I ask you a business model
[00:23:22] question here because looking at the
[00:23:24] strategic landscape um actually I have
[00:23:26] many questions here um one of the
[00:23:28] observations I'd have is if I look at
[00:23:30] one of these like rich voice and action
[00:23:34] agent experiences
[00:23:36] there a lot of uh let's say fortune 500
[00:23:38] global 2000 leaders who listen to the
[00:23:41] pod uh they I think a lot of them are
[00:23:44] going to buy the idea of like I want
[00:23:46] this amazing um automatic like real time
[00:23:50] available 24/7 every language experience
[00:23:53] for my customer that's consistent and
[00:23:56] high quality. The ways I might get there
[00:23:59] include working with a Palunteer or a
[00:24:04] large consulting firm, uh, working with
[00:24:08] 11 or a like platform technology company
[00:24:10] or or like an open AI or something,
[00:24:12] right? Let's talk about that. Uh, or
[00:24:15] working with a sort of more use
[00:24:18] caseoriented company like Sierra, right?
[00:24:20] [clears throat] How do you think about
[00:24:21] how people are making that decision or
[00:24:23] how they should make that decision? the
[00:24:25] so so my past is also in Palunteer so I
[00:24:28] started exactly kind from from that side
[00:24:30] and we do blend a lot of the forward
[00:24:31] deployed engineering inside of the
[00:24:32] company too as I think about the kind of
[00:24:34] our offering and and the customers
[00:24:37] making that choice if you're looking
[00:24:39] just as as a like onepointed solution uh
[00:24:42] and only that one then likely we aren't
[00:24:44] the best choice if you are looking to
[00:24:46] deploy that across a plethora of
[00:24:48] different experiences so be it customer
[00:24:51] support but then you also want internal
[00:24:52] training then you might want to elevate
[00:24:54] your sales sales part and actually
[00:24:55] increase the top line with new
[00:24:57] experiences of how you engage customers
[00:24:59] beyond that kind of reactive piece. Mhm.
[00:25:01] >> Um then it's a great platform to build
[00:25:03] and then we effectively as we engage
[00:25:05] with customers combine that platform
[00:25:07] work with uh with our engineering
[00:25:09] resources to help those companies deploy
[00:25:11] on that or which we also see
[00:25:14] increasingly in um in Fortune 500s G2
[00:25:16] G2000s where they will want to build
[00:25:19] parts of the things themselves because
[00:25:21] they already have a lot of the
[00:25:22] investments in that platform while then
[00:25:25] engage us on some of the the new ones
[00:25:27] and combine those and and and I think
[00:25:29] that our model and the way it's
[00:25:30] different to to a lot of the use case
[00:25:32] specific ones is that our platform is
[00:25:34] relatively open where you can use pieces
[00:25:36] of that platform and not all of them um
[00:25:39] for for those different use cases.
[00:25:41] Palunteer of course will will or or some
[00:25:43] of the consulting companies will have a
[00:25:44] lot more resources to go in the wider
[00:25:47] digital transformation journey. In our
[00:25:49] case, it's like very specific
[00:25:50] conversational agents. It's like if you
[00:25:52] are looking for new interface with
[00:25:54] customers, that's the the best way. And
[00:25:57] um and companies like Sierra phenomenal
[00:25:59] of course on on how they are thinking
[00:26:00] about the the specific pointed uh uh use
[00:26:04] case and the maybe the other piece is uh
[00:26:07] like as we think about our work
[00:26:09] depending on how you are what you are
[00:26:11] optimizing for. So we we have a lot of
[00:26:14] international partners. If you have like
[00:26:15] a a wider geographic user base, great.
[00:26:19] That's what we optimize for. Our voices,
[00:26:20] our languages, our support for
[00:26:22] integrations internationally are just so
[00:26:24] much broader. There's frequently a piece
[00:26:26] that you will look into depending on
[00:26:29] your exact scope, this will be this will
[00:26:31] be a big factor. But I would summarize
[00:26:32] that if you're looking for a solution
[00:26:34] across the set of different use cases
[00:26:36] that you want our engineering help and
[00:26:39] deploy that, then we are the right
[00:26:41] solution and probably the best solution.
[00:26:43] I want to talk a little bit about maybe
[00:26:46] like opening eye and the foundation LLM
[00:26:48] foundation model companies. One of the
[00:26:50] reasons a lot and I called this podcast
[00:26:51] no priors is because we're like okay
[00:26:53] people are making a lot of assumptions
[00:26:55] all the time about how the market is
[00:26:56] going to work and lo and behold like
[00:26:58] many of those assumptions end up being
[00:27:00] nonsense actually and you you you can't
[00:27:03] you have to very much decide your own
[00:27:04] narrative at this point in time. I
[00:27:06] think, correct me if I'm wrong, like in
[00:27:08] 2022 and 23, you probably heard a lot of
[00:27:11] people say like Google can do this and
[00:27:13] OpenAI can do this and like why do you
[00:27:15] get to persist working on voice anyway
[00:27:18] as a general capability? What's the
[00:27:20] answer? That also adds adds a kind of
[00:27:23] another element to to to that the couple
[00:27:25] of the other previous questions where
[00:27:26] whether it's agents work whether it's
[00:27:28] the creative work deploy the value in
[00:27:30] those in those work you need a very
[00:27:32] strong product layer you need the
[00:27:34] integrations you need to help people
[00:27:35] deploy the work which is the most common
[00:27:37] piece but our superpower and our focus
[00:27:40] for a long time was building the
[00:27:42] foundational
[00:27:44] models to actually make that experience
[00:27:46] seamless and as I think about a lot of
[00:27:47] the companies in the market they will
[00:27:50] optimize for a lot of other things and
[00:27:52] that that will be like the
[00:27:53] differentiator um in our case where we
[00:27:56] will make the whole experience
[00:27:58] especially with voice seamless human
[00:28:02] controllable in a in a much better way
[00:28:04] >> and so fundamentally you would argue
[00:28:06] that like the labs just aren't going to
[00:28:08] focus on this and haven't
[00:28:10] >> exactly so I think most of those
[00:28:12] companies and that's the thing about the
[00:28:13] long term it's going to be incredible
[00:28:16] research and incredible product that
[00:28:19] meets customers where they are and work
[00:28:21] backwards from there. I don't think the
[00:28:22] the labs will focus on building that
[00:28:24] product layer that's so important.
[00:28:26] >> But I think the you know part of the
[00:28:28] question that you're asking is like how
[00:28:31] uh or and and and why they haven't done
[00:28:34] even the research part
[00:28:36] >> to the quality that that we've been able
[00:28:37] to as here I'm also biased but we are
[00:28:39] happily beating them on benchmarks with
[00:28:41] text to speech or speech to text or the
[00:28:43] orchestration mechanisms and here credit
[00:28:45] to my co-founder and the team uh that
[00:28:47] they've been able to do it. It's just a
[00:28:49] mighty researchers just continuing their
[00:28:51] work. But I think the main part that I
[00:28:54] think is different in audio space is
[00:28:55] that you don't need the scale as much as
[00:28:58] you need the architectural
[00:29:00] breakthroughs, the model breakthroughs
[00:29:01] to really to really make a a dent. And
[00:29:05] um and we've been able to do that couple
[00:29:07] of times and I think the number of
[00:29:09] people doesn't matter but the people
[00:29:11] that you do does. We think there's maybe
[00:29:13] 50 to 100 researchers in audio space
[00:29:16] that could do it. We think we have
[00:29:18] probably 10 of them um in the company
[00:29:21] that um that are some of the best ones.
[00:29:23] And I think this like obsession of just
[00:29:26] those people working across and then
[00:29:28] actually giving the full focus on the
[00:29:30] company on making them actually work on
[00:29:33] that and bringing their work to
[00:29:34] production, seeing how the users
[00:29:37] interact back was was so important. So
[00:29:39] that's the that's I think how we how we
[00:29:42] been able to create models um better
[00:29:45] than some of the the the top companies
[00:29:46] out there. But you know the truth is
[00:29:48] it's like to large extent is why they
[00:29:50] weren't able to do it is also like an
[00:29:52] interesting we we don't know it's like
[00:29:53] it's a it's a it's uh they are like they
[00:29:56] have such an incredible talent there
[00:29:57] too.
[00:29:58] >> How do you think at the same time about
[00:30:00] um like open source models? anyone you
[00:30:02] ask in the company I think will say that
[00:30:04] same and that's like a narrative we
[00:30:05] think about it's in the long term models
[00:30:08] will commoditize or the differences
[00:30:09] between will be negligible for some use
[00:30:11] cases they will still matter for most
[00:30:13] like the long like the most use cases
[00:30:15] they they won't um
[00:30:17] >> and they'll be broadly available and
[00:30:19] >> they will be broadly available exactly
[00:30:21] and we don't know where that is whether
[00:30:22] it's two years three years four years
[00:30:24] but it's it's going to happen at some
[00:30:26] stage then of course you will have a
[00:30:27] fine tuning layer that will matter a lot
[00:30:29] um on on top of those models but like
[00:30:31] the base models I think will get pretty
[00:30:33] good. Um and that's why for us the
[00:30:35] product piece is so important from the
[00:30:37] company perspective but also from the
[00:30:39] value perspective because if you have a
[00:30:41] model that's great but to actually
[00:30:43] connect your business logic and
[00:30:45] knowledge to um to be able to have the
[00:30:47] right interface for creating a an ad for
[00:30:50] your work or a completely new material
[00:30:52] that's uh that's a very different
[00:30:53] exercise um but open source models are
[00:30:56] getting if I split into two like more of
[00:30:58] that async content narration I think
[00:31:01] narration is pretty much open source is
[00:31:04] great, commercial models are great, the
[00:31:06] differences are are getting smaller on
[00:31:09] the on the out of the box quality. What
[00:31:11] most of the models haven't figured out
[00:31:13] um and I think we we wear is how to make
[00:31:15] them controllable.
[00:31:17] >> So that's the kind of the narration
[00:31:18] piece I think the whole interaction
[00:31:20] piece of how you orchestrate the
[00:31:22] components together whether that's
[00:31:23] cascaded speechto text and lamb text to
[00:31:25] speech approach or whether in the future
[00:31:27] it's a fused approach where you train
[00:31:28] them together. I think this is is good
[00:31:31] for customer support or customer
[00:31:32] experience but it's still away from like
[00:31:36] conversation like we have and like
[00:31:37] passing that Turing test. So I think
[00:31:39] this is still like a at least a year
[00:31:43] like a within a year and then you'll
[00:31:45] have like real time dubbing kind of
[00:31:47] variation of like real-time translation
[00:31:50] conversation and I think that's maybe
[00:31:51] like more two years within two years
[00:31:53] away. You know, a very uncomfortable
[00:31:56] belief that I I feel comfortable having
[00:31:58] this belief, but I think is uncommon in
[00:32:00] the market right now is that actually
[00:32:02] most advantages in technology, like they
[00:32:05] could they could last you a year or they
[00:32:07] could last you 10, but they're not like
[00:32:09] infinitely defensible. And if you think
[00:32:11] about that from a model quality
[00:32:13] perspective or a product perspective,
[00:32:16] they allow you to like serve the
[00:32:18] customer better and build momentum and
[00:32:21] build scale for some period of time. And
[00:32:23] actually that's really powerful over
[00:32:24] time, right? But it's not like a clean
[00:32:27] forever answer. And so I think that
[00:32:29] makes I don't know business people and
[00:32:31] investors uncomfortable.
[00:32:32] >> And I mean it's it's it's it's very true
[00:32:35] as well. [laughter]
[00:32:37] >> The way we I mean the way you think
[00:32:38] about it research is head start. This
[00:32:40] gives us we can give advantage to the
[00:32:42] customer earlier and it's six 12 months
[00:32:45] of advantage. That is also a way for us
[00:32:48] to build a right product layer for you
[00:32:50] to get best of that research. Frequently
[00:32:53] we do that in parallel. So the moment
[00:32:54] the research is out there you have the
[00:32:56] product because we know our initiatives
[00:32:58] we know what the product is. That's
[00:32:59] right. So you have research product in
[00:33:01] parl that extends that. But the kind of
[00:33:03] the thing that will really give that
[00:33:05] long-term value is the ecosystem that
[00:33:07] you create around whether that's the run
[00:33:09] and distribution whether that's the
[00:33:11] collection of voices you can have the
[00:33:12] collection of integrations you can build
[00:33:14] the workflows that you can build. Um
[00:33:16] like I think that's that's the way we
[00:33:18] kind of sequence that in our mind that
[00:33:19] research product ecosystem that we built
[00:33:21] and um and research all it is is a is a
[00:33:24] head start and being able to like
[00:33:26] accelerate the future a little bit
[00:33:28] closer. I think that's a really powerful
[00:33:29] insight especially if you know the
[00:33:32] research and the research team and the
[00:33:34] company team believe that as well
[00:33:36] internally
[00:33:37] >> it's it's it's I think the piece that we
[00:33:39] what's like interesting for us is u and
[00:33:41] I think this is like the the the big
[00:33:43] questions for all companies that do
[00:33:45] research in product is do you wait for
[00:33:47] research or do you do like a a product
[00:33:50] change uh or even not only research
[00:33:52] product companies like do you wait for
[00:33:53] someone else to do the research because
[00:33:54] the timeline for that isn't clear is it
[00:33:56] 3 months 6 months 12 months don't know
[00:33:58] exactly what it will do which is the
[00:34:00] hard choice of like do I invest into
[00:34:01] product layer or do I just wait more for
[00:34:03] the research so like in our case we
[00:34:05] internally let all the product teams the
[00:34:08] research initiative so we can paralyze
[00:34:10] that work uh but we don't hold them that
[00:34:12] if if a product team thinks we should
[00:34:14] deliver value to the customer by doing
[00:34:15] something different they can and rough
[00:34:18] rule of thumb is like three months if we
[00:34:20] think it's going to be longer than three
[00:34:21] months we will probably build it if it's
[00:34:23] less than that we probably won't
[00:34:25] >> can you talk about some of the research
[00:34:26] that you're doing now and and how you
[00:34:28] think about like the cadence of delivery
[00:34:29] and what's worth working on.
[00:34:31] >> We have now number of of different
[00:34:33] initiatives across the audio space and
[00:34:35] there are there are kind of two big
[00:34:36] buckets and and and roughly they will
[00:34:38] relate to that creative and agent side.
[00:34:40] On the creative side what this means uh
[00:34:43] with the texttospech models that are
[00:34:44] controllable. Uh we then added
[00:34:46] speechtoext model that transcribes in a
[00:34:48] high accurate way but across a low
[00:34:51] resource languages as well. So covering
[00:34:53] almost 100 languages. then created a
[00:34:55] music model, a fully licensed music
[00:34:56] model. Um, and as you think about the
[00:34:58] future is how those models will also
[00:35:00] interact with some of the visual space.
[00:35:02] So that's uh a lot of effort and how you
[00:35:05] can get a best of audio and then
[00:35:07] potentially combine that with existing
[00:35:09] video that you have to to to really have
[00:35:11] the best delivery. And then on the agent
[00:35:13] side, it's of course how you optimize
[00:35:16] the real-time speech to text, real-time
[00:35:18] text to speech. We just released our
[00:35:20] speechto text model scribe v2 which is
[00:35:23] under 150 milliseconds 93.5% accuracy
[00:35:27] across the top 30 languages on on flares
[00:35:29] and it's only top 30 here because we
[00:35:31] serve so many others but most of the
[00:35:32] people don't so uh so it's uh so it's
[00:35:35] beating beating the the all the models
[00:35:37] on on benchmarks but as you think about
[00:35:38] the future it's also the orchestration
[00:35:40] piece of how you bring speechto text lm
[00:35:43] and text to speech we are releasing
[00:35:45] we'll be releasing over the next couple
[00:35:47] of months a new orchestration mechanism
[00:35:49] that will lower the end to end part um
[00:35:52] we think in a great way. But second
[00:35:54] thing which is what is so hard is it's
[00:35:57] not going to only allow you to combine
[00:35:58] those pieces but add also the emotional
[00:36:01] context of the conversation so you can
[00:36:03] actually uh respond with the model and
[00:36:06] we think and more expressive in a in a
[00:36:07] better way. And in the future and
[00:36:09] something we're investing is paralyzing
[00:36:12] a speechtospech more fused approach as
[00:36:13] well. And of course depending on the use
[00:36:15] case if you are like enterprise reliable
[00:36:17] use case the cascaded approach is the
[00:36:19] approach for the next year too
[00:36:21] >> has more structure yeah
[00:36:22] >> more structure you have more uh
[00:36:24] visibility into each of the steps it's
[00:36:25] reliable you can I'll call tools if
[00:36:28] you're think more expressive and can
[00:36:30] hallucinate speech to speech might be
[00:36:31] the choice and maybe over time you'll
[00:36:33] see them the kind of go one over over
[00:36:36] another depending on the on the industry
[00:36:37] but that's like a huge investment on our
[00:36:39] side which is where the foundation of
[00:36:41] all the platform and and and the main
[00:36:43] part that we are continually investing
[00:36:45] in is is is kind of plethora of
[00:36:46] different models that combine the best
[00:36:49] of audio with some of the best of the
[00:36:50] other modalities together.
[00:36:52] >> I want to take uh our last few minutes
[00:36:54] and ask you a few questions about just
[00:36:56] the future that I think you'll have a
[00:36:58] really good point of view on given you
[00:36:59] think about voice and audio all the
[00:37:01] time. What do you think of AI
[00:37:02] companions?
[00:37:04] >> I think they will be a big thing and
[00:37:07] exist in a big way. not something I'm
[00:37:09] personally excited about or something
[00:37:10] that we spend much uh time on but uh I
[00:37:14] think the whole line of of what's a
[00:37:17] assistant companion character that you
[00:37:21] enjoy as part of experience will kind of
[00:37:24] blurry and blend to a large extent
[00:37:26] >> they can be very common but you're not
[00:37:28] like enthusiastic personally about it
[00:37:30] >> I'm more excited about like more of um
[00:37:33] the Jarvis version of that or like like
[00:37:35] more of like I have a super assistant
[00:37:38] superpower. It's like
[00:37:39] >> versus the social version
[00:37:40] >> versus the [clears throat] social
[00:37:41] version that's like I think it's it just
[00:37:43] would be like such an incredible unlock
[00:37:45] and and it also like is in a something
[00:37:48] blending in that person context like I
[00:37:50] would love to start the day and like
[00:37:52] someone that understands me and like
[00:37:53] start and tell me what's like relevant
[00:37:54] to me and open the blinds and then like
[00:37:57] tell me about the weather and the
[00:37:58] sunshine is and play music straight
[00:38:00] away.
[00:38:01] >> It's going to happen.
[00:38:01] >> It's going to happen. That I'm excited
[00:38:03] for. I think the companion um use cases
[00:38:05] will will will mention solving
[00:38:07] loneliness and in that part I think
[00:38:10] that's one way maybe there are like
[00:38:11] different ways of engaging people back I
[00:38:13] do I do think there will be like an
[00:38:15] interesting future even if you think
[00:38:16] about education where you will have
[00:38:18] superpower with learning from AI tutors
[00:38:20] but I think on the flip side of that and
[00:38:22] I think this will like that's my
[00:38:24] personal take you will have education
[00:38:28] good percent of time spent with AI
[00:38:30] tutors but then explicit percent of time
[00:38:33] spent and without any technology human
[00:38:35] to human.
[00:38:36] >> So you can you can kind of learn that
[00:38:38] part too.
[00:38:38] >> Yeah, I think this is the correct model.
[00:38:40] Um both in terms of like emotional
[00:38:43] guidance and coaching and um you know uh
[00:38:47] guard rails, right? As well as like
[00:38:49] peerto-peer. Um
[00:38:51] >> exactly. What do you think about um
[00:38:53] dictation or what happens in terms of
[00:38:55] how we like control uh technology that
[00:38:58] isn't necessarily personified as well
[00:39:01] >> or does it just all become personified?
[00:39:03] >> I think not all personified. I think
[00:39:05] like some you know communicating within
[00:39:07] oven and and home probably will like
[00:39:09] stay pretty static and
[00:39:10] >> or code I might just
[00:39:11] >> Yeah, exactly. like you don't probably
[00:39:13] need that much of of like additional
[00:39:15] emotional input
[00:39:17] >> but uh but I think it's yeah it's going
[00:39:18] to be huge part where like in a way what
[00:39:21] I hope will happen is you will have
[00:39:23] ability to like stay more immersed in
[00:39:25] the real life with the devices going
[00:39:27] into back into the pocket back into some
[00:39:29] version of a um attached element um
[00:39:32] assuming that's that's in in the right
[00:39:34] setting and um and that kind of acts on
[00:39:37] your behalf and in many ways like let's
[00:39:39] say dictation it's as Karpati says
[00:39:41] decade of agents. Let's let's let's call
[00:39:43] it a decade. Then you'll have a decade
[00:39:45] of of robots. If you are interacting
[00:39:47] with robots, of course, voice will be
[00:39:49] the input and the output as one of the
[00:39:51] key interfaces. So, you will need that
[00:39:53] dictation as a as a huge part. But
[00:39:55] similarly,
[00:39:56] >> I think the robot's going to be
[00:39:57] personified.
[00:39:58] >> Yeah. 100% 100%. Yeah. No, like I think
[00:40:02] I think most of the use cases will be
[00:40:04] personified.
[00:40:05] >> Okay. Last one. What's like one thing
[00:40:07] that you've seen already exist today or
[00:40:09] if you project out a few years will
[00:40:12] change about how we interact with
[00:40:14] content maybe it's like personalized
[00:40:16] voice content or um just something
[00:40:19] people are going to do with with AI
[00:40:20] voice that they don't do today or that
[00:40:22] not everybody knows about.
[00:40:24] >> I think this still the biggest one that
[00:40:25] hasn't yet kicked into the the the
[00:40:28] system is like how education will be
[00:40:29] done. I think this go like I think
[00:40:32] learning with AI will with voice where
[00:40:35] you it's like on your headphone or in a
[00:40:37] speaker it's just going to be such a big
[00:40:40] thing where you have like your own
[00:40:41] teacher on demand and who understands
[00:40:44] you very personified and kind of
[00:40:46] delivers the right content through your
[00:40:47] life I think this will be one of the
[00:40:49] biggest use cases uh uh and I don't
[00:40:52] think it happened yet I think we have
[00:40:54] see of course some of the commercial
[00:40:55] partners but like schools universities
[00:40:58] how that's deployed in a safeguarded way
[00:41:00] in a way that like supports the other
[00:41:01] part of the education, the social part
[00:41:03] of education. I think all of that will
[00:41:04] will evolve and maybe there's a cool
[00:41:06] version of that where you have like
[00:41:08] Richard Fineman or Albert Einstein
[00:41:10] deliver those lecture notes or other
[00:41:11] teachers that you love. It's it's it
[00:41:13] will be sick.
[00:41:14] >> It's a great note to end on. Thanks for
[00:41:15] doing this, Marty.
[00:41:16] >> Thanks so much.
[00:41:20] >> Find us on Twitter at No Prior Pod.
[00:41:22] Subscribe to our YouTube [music] channel
[00:41:24] if you want to see our faces. Follow the
[00:41:26] show on Apple Podcasts, Spotify, or
[00:41:28] wherever you listen. That way, you get a
[00:41:30] new episode every week. And sign up for
[00:41:32] emails [music] or find transcripts for
[00:41:33] every episode at no-briers.com.
