[00:00:00] There's this fear that, oh, if I ship
[00:00:02] something that's like too rough, people
[00:00:03] are just going to be like make up their
[00:00:04] mind and then not want to use the
[00:00:06] product later when it got better. The
[00:00:08] only way that would happen is if you're
[00:00:09] super slow. Whereas, if you really
[00:00:11] follow up with the user immediately and
[00:00:13] they're excited to try it again, then
[00:00:14] you don't really have that problem.
[00:00:16] >> Anything that kind of trades off speed
[00:00:17] needs to be really carefully thought
[00:00:19] through.
[00:00:19] >> By the time folks are done debating two
[00:00:21] good options, I will probably have
[00:00:22] execute on 10. Do I have any emails I
[00:00:26] need to respond to today? [music] and it
[00:00:28] will like review my mailbox and identify
[00:00:30] anything that's like urgent to respond
[00:00:33] to today. I've just gotten like 100%
[00:00:36] more effective in my in my work because
[00:00:39] I now have this.
[00:00:42] >> Okay, welcome everyone. I'm really
[00:00:44] excited to have back on the podcast
[00:00:45] Jana, my friend and now head of AI at
[00:00:48] Amplitude. You know, I I think Jana is
[00:00:50] like top 1% chat GP power user. So
[00:00:53] really excited to talk to her about how
[00:00:54] she uses AI for work and finally what
[00:00:57] product leaders can learn from founders
[00:00:59] since she's worn both hats. So welcome
[00:01:01] Jana.
[00:01:02] >> Thanks so much for having me. Super
[00:01:03] excited to chat.
[00:01:04] >> Yeah, why don't we start with the uh
[00:01:06] most recent topic. You know over the
[00:01:08] weekend I I tweeted something about I
[00:01:10] tweeted something about like how cursor
[00:01:12] scale to billion uh valuation without
[00:01:15] any PMs and then it became like a big
[00:01:17] viral post about how like PMs are not
[00:01:20] valuable anymore. [laughter]
[00:01:22] So yeah, so you've been both a founder
[00:01:24] and now a product leader at a large
[00:01:26] company. I guess what is different about
[00:01:28] these two roles and what what can
[00:01:30] product leaders learn more from
[00:01:31] founders?
[00:01:32] >> As a product leader generally, which is
[00:01:34] kind of what I was before before
[00:01:35] starting Grapple, you do have to kind of
[00:01:38] hone in on your product sense and have
[00:01:41] good product strategy and manage PMs and
[00:01:43] all that stuff. But it's sort of like a
[00:01:45] much more isolated role I would say in
[00:01:48] in sort of the organization.
[00:01:49] >> Mh. Whereas as a founder obviously it's
[00:01:52] your baby, right? Like Franchesci talks
[00:01:54] about we're like the biological parents
[00:01:56] of the company. So it's just a
[00:01:58] completely different role where you're
[00:02:00] you have intuition around what's going
[00:02:03] to be good for the company in a in a
[00:02:04] completely different way. Not just from
[00:02:06] a product perspective, just generally in
[00:02:08] every possible way. And I think coming
[00:02:10] in now into another organization where I
[00:02:13] am not the biological parent of this
[00:02:15] company yet I kind of am brought in to
[00:02:18] still be as much of a founder as I can
[00:02:21] be. That's and I think a lot of like
[00:02:24] whenever whenever like larger companies
[00:02:26] acquire startups they do it and in our
[00:02:28] case we were acquired for the product
[00:02:30] we're also acquired for the team and so
[00:02:32] in some sense my task is to try to kind
[00:02:34] of like maintain as much of my like
[00:02:36] founder perspective as possible and and
[00:02:39] I'll say you know after being a founder
[00:02:41] it's very easy to do that it's actually
[00:02:42] really really hard to try to fit into an
[00:02:44] organization and have any other kind of
[00:02:45] role and so you kind of come in and
[00:02:47] you're sort of
[00:02:48] >> you can't help thinking how you know how
[00:02:50] would I want this company to run like if
[00:02:53] this was my company how would I want it
[00:02:54] to run and then like just trying to act
[00:02:56] on that.
[00:02:56] >> Okay. So, so like there's a lot of talk
[00:02:58] about how uh as IC's they have to, you
[00:03:01] know, IC have to wear multiple hats. You
[00:03:02] can't just be a designer or PM anymore.
[00:03:04] You got to learn how to prototype. You
[00:03:06] got to learn how to do a little bit of
[00:03:07] everything. So, I guess even at the
[00:03:09] product leader or exec level, you should
[00:03:10] also
[00:03:11] >> well probably even more, right? You
[00:03:13] should probably be aware of what's going
[00:03:14] on with marketing and engineering and
[00:03:16] everything else.
[00:03:17] >> Absolutely. Absolutely. I I think I
[00:03:19] think that's actually like the
[00:03:20] interesting thing about product is that
[00:03:21] at any stage in product whether you're a
[00:03:23] product leader or you're like a product
[00:03:25] I see a PM really you have a super cross
[00:03:29] functional role even though like as PMs
[00:03:31] we often at least historically have been
[00:03:33] very like here's what defines my role at
[00:03:36] my organization because like PM at every
[00:03:38] organization is different now absolutely
[00:03:40] you kind of need to be super
[00:03:41] crossunctional like not crossunctional
[00:03:43] crossunctional makes it sound like
[00:03:45] you're like coordinating with other
[00:03:46] people whereas is actually [snorts] you
[00:03:48] do need to do you need to do that work
[00:03:50] yourself like you have to design you
[00:03:52] have to user research you have to try to
[00:03:55] write code as much as possible
[00:03:56] particularly now that there's so many
[00:03:57] tools where you can ship code so I think
[00:04:00] that it's become pretty inevitable to be
[00:04:02] all the things um and I think this is a
[00:04:05] bad thing I think that's actually like
[00:04:06] it gets everyone moving much faster and
[00:04:08] it make sure that people are like feel
[00:04:10] much more ownership because you're
[00:04:12] you're never sort of like this is my
[00:04:14] role and everything else is like someone
[00:04:16] else will do that. Yeah, that that is
[00:04:17] the key because I was going to follow up
[00:04:19] with you on this crossf functional
[00:04:20] thing, right? Because because uh you can
[00:04:23] like like a lot of PMs at larger
[00:04:26] companies feel like kind of like a
[00:04:27] glorified cross functional secretary or
[00:04:30] you know kind of like trying to align
[00:04:31] like 10 different stakeholders trying to
[00:04:32] align the leadership and then they have
[00:04:34] all these internal debates and and like
[00:04:36] document writing, right? And and like
[00:04:37] trying to get everyone to agree on the
[00:04:39] same decision on a path forward.
[00:04:41] >> Yeah.
[00:04:41] >> I don't think that's what you're talking
[00:04:42] about, right? Or like
[00:04:43] >> No. Yeah.
[00:04:44] >> Yeah. Yes. Absolutely not. I'm
[00:04:46] definitely not talking about that. I
[00:04:47] mean, I I think I've forgotten just how
[00:04:49] much of that there is and and now being
[00:04:51] being back at a at at a bigger company,
[00:04:53] I sort of realized I am, you know, I'm
[00:04:55] most certainly not the debate girl and
[00:04:57] I'm not I'm not going to be writing any
[00:04:58] like docs uh to coordinate stakeholders.
[00:05:02] Uh and I think that, you know, by by the
[00:05:04] time folks are done debating two good
[00:05:06] options, I will probably have executed
[00:05:07] on 10. And I think that that's how
[00:05:09] founders move. And I think that every PM
[00:05:11] should really do that given that's kind
[00:05:14] of how fast AI moves.
[00:05:15] >> But how do you get the freedom or the
[00:05:16] agency to just like ship stuff?
[00:05:18] >> Uh you know actually now at Amplitude we
[00:05:22] or Pens has recently banned decisions by
[00:05:25] committee and so specifically to enable
[00:05:28] PMs and engineers to be kind of owners
[00:05:31] and be able to move fast and be able to
[00:05:33] ship fast. we've had we've been able to
[00:05:35] ship particularly in in with the AI
[00:05:38] products but really um any any product
[00:05:41] have been able to move much much faster
[00:05:42] as a result of that and I think that
[00:05:44] it's important that leaders enable their
[00:05:47] teams to move fast and and have that
[00:05:50] ownership and yeah it's kind of hard to
[00:05:52] do as like at at the IC level to say
[00:05:56] actually my company's now going to be AI
[00:05:57] native
[00:05:59] >> and I'm gonna be AI native and I'm not
[00:06:01] going to talk to anyone I'm just going
[00:06:02] to go and ship I I think that that is of
[00:06:04] course incredibly difficult. You kind of
[00:06:06] need to get support to be able to do
[00:06:08] that. So it does need to come from from
[00:06:09] the top and I think probably if it's not
[00:06:11] coming from like the founder CEO, it's
[00:06:14] definitely something that product
[00:06:16] leaders need to advocate for so that
[00:06:18] their like teams can ship at pace that's
[00:06:20] like relevant today and and not kind of
[00:06:22] like become outdated.
[00:06:24] >> What led him to ban this uh decision by
[00:06:25] committee? Was this move like moving too
[00:06:27] slow or like
[00:06:28] >> Yeah. No, I mean definitely uh it
[00:06:31] definitely was a desire to be AI native
[00:06:34] and that's kind of why like why he
[00:06:36] acquired essentially multiple startups
[00:06:38] at the same time. There was sort of the
[00:06:40] idea was to bring in more AI talent and
[00:06:43] folks with experience moving at that at
[00:06:45] that speed and then get the whole
[00:06:46] organization to move the same. Um so
[00:06:49] sort of a very kind of big strategic
[00:06:50] change that was kind of just one piece
[00:06:52] of the bigger puzzle.
[00:06:53] >> You know Amplitude is like a very
[00:06:55] successful company, right? got is worth
[00:06:56] billions of dollars. But I I bet that
[00:06:58] Spence probably looks fondly back on the
[00:07:00] early days where he can just like, you
[00:07:02] know, ship stuff and move fast and
[00:07:03] [laughter] he probably just wants to get
[00:07:05] this company back to that state. That's
[00:07:07] probably what he wants.
[00:07:08] >> I think that's part of the story. I
[00:07:10] think the other piece is that he really
[00:07:12] he's very cognizant of how the world is
[00:07:15] changing and what companies are sort of
[00:07:17] doing well and what companies are not.
[00:07:20] And there are bigger companies including
[00:07:22] public companies that are adopting a AI
[00:07:26] native approach and and are really kind
[00:07:28] of changing how their teams move
[00:07:30] >> and ship. And it's just it looks
[00:07:31] different from kind of what public
[00:07:33] companies were doing like two years ago.
[00:07:34] Um and and I think it's been very kind
[00:07:37] of strategic and in making sure that
[00:07:39] Amplitude is in that boat as opposed to
[00:07:41] kind of the companies that we'll need to
[00:07:42] kind of be catching now.
[00:07:43] >> I mean keep saying AI native but it's
[00:07:45] really like a culture thing, right? It's
[00:07:47] like I think this new breed of companies
[00:07:48] like cursor and um you know openai and
[00:07:52] anthropic and all these other companies
[00:07:53] are basically trying to keep headcount
[00:07:55] as low as possible and just try to like
[00:07:57] empower everyone and to just work with
[00:07:59] AI and just figure stuff out and ship
[00:08:01] because if if if you don't ship fast
[00:08:03] into companies then you're the company's
[00:08:05] going to die. [laughter]
[00:08:06] >> Exactly.
[00:08:07] >> So you kind have have to do it. Yeah.
[00:08:08] >> There's no guarantees right now, right?
[00:08:10] Like you kind of have to you have to
[00:08:11] move as fast as AI startups are moving
[00:08:14] because nothing is taken for granted.
[00:08:16] Got it. So, so, so then uh you know, you
[00:08:18] probably have a bunch of PMs or other
[00:08:19] folks reporting to you. How do you
[00:08:21] encourage them to move fast and maybe
[00:08:22] make some mistakes and you know, not
[00:08:24] feel bad about it?
[00:08:25] >> I think the best way to encourage folks
[00:08:28] to move fast is to move fast is sort of
[00:08:31] like lead by example and and show, okay,
[00:08:33] here's a decision we need to make. How
[00:08:35] would we make this decision in a startup
[00:08:36] versus how would you make this decision
[00:08:38] in a big company? If I can kind of
[00:08:39] primarily show what how would I approach
[00:08:42] this? I think I' I've done a lot of that
[00:08:43] recently in terms of just like okay we
[00:08:45] have this launch. how would I do this
[00:08:47] launch? And I'm I'm just I'm going to do
[00:08:48] this launch the way I would do this
[00:08:49] launch so that other people can see that
[00:08:51] it can be done in a certain way and it's
[00:08:53] going to be faster and and better and uh
[00:08:55] and it will leverage AI in like 90% more
[00:08:58] places than uh than you would in a in a
[00:09:01] bigger company and and folks are getting
[00:09:03] to see that and they're so like okay I
[00:09:04] can just next time we're doing some
[00:09:06] other launch we can do that too and um
[00:09:08] you know so I think it's I think it's a
[00:09:09] lot of like killing instead of trying to
[00:09:12] like win an argument because I think
[00:09:14] that like otherwise it ends up being the
[00:09:16] default is to debate things, right? And
[00:09:19] there's no time to debate things. So,
[00:09:20] the only way you can you do it is to
[00:09:23] show that something works and um and
[00:09:26] then get people excited about doing it
[00:09:27] too.
[00:09:28] >> Yeah, that's a good point. And like I
[00:09:29] also feel like there's should have like
[00:09:31] higher tolerance for fail failures,
[00:09:33] right? Because um if you move fast like
[00:09:35] some things are not going to work out or
[00:09:36] maybe there's some mistakes and and then
[00:09:38] like and then people who are like used
[00:09:40] to process are like you know, hey, I
[00:09:41] told you so so let's add like five more
[00:09:43] steps to this process. But like that
[00:09:45] that's that's like a I I I think
[00:09:47] anything that kind of trades off speed
[00:09:49] needs to be really carefully thought
[00:09:50] through basically you know
[00:09:52] >> I I completely agree you know I think
[00:09:54] that one thing that is really helpful to
[00:09:56] show particularly around failure is that
[00:09:59] often times when you fail it's an
[00:10:01] opportunity to do even better
[00:10:03] particularly when you fail with customer
[00:10:05] scam you are customers and users and you
[00:10:07] really act fast on the failure. So, so,
[00:10:10] so, so one thing is sort of like if you
[00:10:12] if you ship something and there's some
[00:10:14] kind of like rough edges that you can
[00:10:16] work out with with the users quickly as
[00:10:18] they're reporting it. Uh, the reaction
[00:10:20] of a user who had some initial
[00:10:22] frustration, reported it to you, and you
[00:10:24] fixed it within like 15 minutes is going
[00:10:27] to be so much better than a user who
[00:10:28] just was like me happy, you know, it was
[00:10:31] shipped the first time. like the the
[00:10:33] impression that oh I I I came in I said
[00:10:35] I needed this to be better and and the
[00:10:37] company actually went in and did that
[00:10:39] and they followed up with me. Those
[00:10:40] users tend to be like your strongest
[00:10:42] allies. So I think that that's another
[00:10:43] way of showing like actually feeling a
[00:10:45] climb as long as you constantly are
[00:10:47] readjusting and and acting fast.
[00:10:48] >> Yeah. Like if you're co-creating the
[00:10:50] stuff with your users and you're
[00:10:51] listening to them and fixing all their
[00:10:52] bugs and feedback like yeah they're
[00:10:54] probably even a stronger allies than if
[00:10:56] you just got a perfect product right off
[00:10:57] the bat. So
[00:10:58] >> yeah. Yes. Yeah. Yeah. I don't know why
[00:11:00] more companies don't do this like just
[00:11:02] just like you know just share all the
[00:11:03] stuff with users along the way and like
[00:11:05] you know you can like ship to more
[00:11:06] concentric circles as a product gets
[00:11:08] better. I mean even even like OpenAI
[00:11:11] devices right like they're they're like
[00:11:12] super successful and they like they
[00:11:14] launch features pretty they're pretty
[00:11:16] MVP stuff that they launch and then they
[00:11:18] iterate and get better along the way.
[00:11:21] >> Yeah. Yeah. And and I think that the
[00:11:23] thing is there's this fear that oh if I
[00:11:25] ship something that's like too rough and
[00:11:27] ready that people are just going to be
[00:11:29] like make up their mind and then then
[00:11:30] not want to use the product later when
[00:11:32] it got better. And I think the the key
[00:11:34] is to make sure that's you don't lose
[00:11:36] their interest along the way. Like the
[00:11:38] only way that would happen is if you're
[00:11:40] super slow whereas if you really follow
[00:11:42] up with the user immediately and make
[00:11:43] sure that they get an update and then
[00:11:45] they are excited to to try it again then
[00:11:47] you don't really have that problem. And
[00:11:49] that I think that's what Openai has done
[00:11:50] well, right? Like they ship things and
[00:11:52] then if there's like some things that
[00:11:53] doesn't work the way you want the fast
[00:11:56] follows happen like the next day, right?
[00:11:58] Or even the same day. And that's really
[00:12:00] important and they're really like vocal
[00:12:01] about it and make sure everyone knows
[00:12:02] and um things like that. I think that
[00:12:04] that's not how uh companies were used to
[00:12:07] adjusting for failure. And so I think
[00:12:10] the expectation is just different.
[00:12:11] >> Yeah, that's a good point. It's like
[00:12:13] it's like you know if you sell me
[00:12:14] something and it's like crappy and I'm
[00:12:16] like hey y this sucks. [laughter] Yeah.
[00:12:18] >> But but then but then you actually
[00:12:19] listen to me and I make it better. Then
[00:12:21] I'm like, "Oh, okay. She actually
[00:12:22] cares." So then I I'll stick around for
[00:12:25] a little bit longer.
[00:12:26] >> Yeah. [laughter] In particular, if I
[00:12:27] move fast, then you understand that the
[00:12:29] reason sucked a little bit to begin with
[00:12:31] was because I was moving fast. And you
[00:12:32] sort of started appreciating that that
[00:12:34] we were like, "Okay, this is cool. It's
[00:12:35] like moving very very fast." Like
[00:12:37] imagine how good it's going to be in a
[00:12:39] year if it keeps moving like this,
[00:12:40] right? It just sets a very very
[00:12:42] different tone and expectation around
[00:12:44] everything versus like slowm moving
[00:12:46] things that are just like polishing
[00:12:47] things to perfection. By the time it's
[00:12:49] done polishing, it's like not even the
[00:12:50] thing you wanted.
[00:12:51] >> You ship something and then people are
[00:12:52] reacting to it and like you just like
[00:12:54] you wait for like a press release or
[00:12:55] something. It's like [laughter]
[00:12:57] >> Yeah. Yeah. Yeah. Yeah.
[00:12:58] >> Yeah. Yeah. It's you got to be active. I
[00:13:00] think the issue is that if you're like
[00:13:03] optimizing for avoiding failure at any
[00:13:06] cost, you really are optimizing for
[00:13:08] avoiding any kind of discoverability or
[00:13:11] adoption because because ultimately it
[00:13:13] it ends up being like if you you know
[00:13:15] you polished for too long and you're too
[00:13:18] careful and and ultimately that's not
[00:13:21] that's not how you win like it's really
[00:13:23] really hard to win like that.
[00:13:24] >> Yeah. I mean I I think in defense of
[00:13:26] like polishing stuff like you know like
[00:13:28] I I feel like uh you can roll out to
[00:13:31] like 10 users like a really crappy
[00:13:32] product and give their feedback and you
[00:13:34] polish a little bit more and roll it to
[00:13:35] 100 and slowly get it more and more. Uh
[00:13:38] like you don't have to roll out like a
[00:13:39] super crappy product to like all the
[00:13:40] users right away. [laughter] So that's
[00:13:42] part of No, no. Yeah. Sorry. I I I
[00:13:46] should have I should have been clear. I
[00:13:47] think that you should definitely have
[00:13:48] the product be as polished as you can at
[00:13:51] the speed that you want to be moving at,
[00:13:52] but you can't obsess over it being like
[00:13:54] absolutely perfect like until until you
[00:13:57] like roll it out to any users. Like
[00:13:59] that's the problem.
[00:14:00] >> I think there's a difference between
[00:14:01] polishing with like real customers, even
[00:14:03] like 10 customers versus polishing
[00:14:05] internally through like debates and like
[00:14:07] trying to like you know just trying to
[00:14:08] get everyone aligned and and then you
[00:14:11] you have like a super compromised crappy
[00:14:13] product.
[00:14:13] >> Yes. Exactly.
[00:14:15] >> Yeah. Yeah. And and I think that that's
[00:14:17] that's such a great point because there
[00:14:19] is this feeling internally that oh we're
[00:14:21] making progress. We're aligning all of
[00:14:22] these people like
[00:14:24] >> but really it's just a bunch of people
[00:14:26] who love being right and so they're all
[00:14:28] trying to be right and and then they get
[00:14:31] like [snorts] some amount of like
[00:14:33] [laughter]
[00:14:33] >> I don't know satisfaction over how much
[00:14:35] they were right in that conversation but
[00:14:37] really there's like actually zero
[00:14:39] progress.
[00:14:40] >> Yeah. Because you never know. You're not
[00:14:41] the customer. You're not the customer.
[00:14:43] So
[00:14:44] >> yeah.
[00:14:44] >> Yeah. This episode is brought to you by
[00:14:46] Optimize the problem in marketing
[00:14:48] usually isn't a lack of ideas, it's a
[00:14:50] [music] lack of time. If your to-do list
[00:14:52] keeps getting away from you, then take a
[00:14:54] look at Optimize the Oppo, an AI agent
[00:14:56] platform [music] built specifically for
[00:14:57] marketing. With OPPO, you can use AI
[00:14:59] agents for SEO and geo recommendations,
[00:15:02] AB testing, [music] website analysis,
[00:15:03] and much more. OPPO knows your brand
[00:15:05] inside and out, and plugs into your
[00:15:07] existing tools and data systems so that
[00:15:09] you can save time on labor intensive
[00:15:11] feature testing, reporting, and more.
[00:15:13] see what it can take off your plate at
[00:15:15] optimizely.com/ai.
[00:15:17] Now back to our episode.
[00:15:19] >> You're open AI and chat power user. So
[00:15:21] let's talk about how you use uh this
[00:15:24] stuff to kind of like you know do your
[00:15:25] job or like you know
[00:15:27] >> I do a lot of AI prototyping which isn't
[00:15:29] particularly new and and and lots of
[00:15:31] folks do that. I will say that probably
[00:15:34] what may be a little bit unique in how I
[00:15:36] do it is that usually when I'm doing an
[00:15:38] in the eye prototype other than when I'm
[00:15:40] doing it just for myself to see what
[00:15:42] what it would look like I'm doing it to
[00:15:43] show it to customers and I will
[00:15:45] oftentimes will have a prototype that
[00:15:47] I'll u jump on a customer call get lots
[00:15:50] of feedback from that call and then
[00:15:52] immediately I usually will take that
[00:15:53] feedback and iterate on the prototype
[00:15:56] and incorporate all the feedback before
[00:15:58] my next call and then I'm on the next
[00:16:00] customer call now they're looking at a
[00:16:02] completely different prototype that's
[00:16:04] been adjusted based on the first
[00:16:05] customer and then I keep like having
[00:16:07] those sort of like iteration cycles and
[00:16:09] I feel like that's something that was
[00:16:11] you know completely impossible to do
[00:16:13] before. You would always have just the
[00:16:15] one prototype and then you would show
[00:16:16] that prototype to like 10 customers and
[00:16:19] then you would never know that if the
[00:16:21] stuff that the c the first customer told
[00:16:23] you is it actually resonating with other
[00:16:25] people or like now you kind of have to
[00:16:27] like reconcile all the feedback you've
[00:16:29] been getting. it's really really hard to
[00:16:31] know is it actually like impactful. I
[00:16:33] think now you can move much much faster
[00:16:34] with like that those are like iteration
[00:16:36] cycles. So that's been that's been a
[00:16:38] really good one for me. Another has been
[00:16:40] to use Sora a lot in like marketing
[00:16:43] collateral. We we just did the launch of
[00:16:45] EI feedback. We ended up using a lot of
[00:16:47] Sora videos and and also not Sora
[00:16:51] videos. We had actual like full on like
[00:16:53] recorded demos of me showing the product
[00:16:56] which you know I've done a lot in the
[00:16:58] past but and have always had that in
[00:16:59] launches and then we had just like
[00:17:01] really fun sort of videos and it was
[00:17:04] really interesting to see the engagement
[00:17:06] on social and how it was different for
[00:17:09] those two types of formats because for
[00:17:12] any kind of videos on social I don't
[00:17:14] know like I'm sure you you've looked at
[00:17:16] this too for when you have a video
[00:17:19] snippet usually by the end of the video
[00:17:21] when you look at the the analytic or for
[00:17:23] the video very very few people have
[00:17:26] watched it through the end. It's like
[00:17:28] the drop off is kind of crazy on Twitter
[00:17:30] but for sort the sort of videos was
[00:17:32] actually sort of like 50% sometimes
[00:17:34] above 50% were watching the whole video
[00:17:37] through the end which was incredible to
[00:17:39] see. I've never seen data like that
[00:17:41] before. [laughter]
[00:17:43] >> I don't know how I actually had someone
[00:17:45] comment on Twitter and was like this is
[00:17:47] incredible post. I like I I I came for
[00:17:50] the video I and then stayed for the copy
[00:17:52] and I was like what was it about the
[00:17:53] video because I was sort of like at
[00:17:55] right at that time I was looking at the
[00:17:57] analytics and I was like what that's
[00:17:58] that's really fascinating like I'm sort
[00:18:00] of like so curious why is this different
[00:18:01] and he was like well you know I kept
[00:18:03] watching the video and I was like is
[00:18:04] this AI is it not AI definitely AI
[00:18:07] actually maybe not AI he kept having
[00:18:10] like that debate in his head of like am
[00:18:11] I what am I looking what am I watching
[00:18:14] um and and I just thought it was really
[00:18:15] really interesting it's just like
[00:18:16] completely different way of engaging
[00:18:17] being hooks.
[00:18:18] >> What kind of sort of videos do you make
[00:18:20] for the product? Like it's not a product
[00:18:21] demo, right? It's like people using the
[00:18:23] product or
[00:18:24] >> No, they're just kind of like funny
[00:18:25] videos like about related topics. And so
[00:18:28] this particular one was uh a video of me
[00:18:32] at the cemetery and [snorts] like
[00:18:34] leaving flowers on a grave for NPS. And
[00:18:37] so it was like a stone that said like um
[00:18:40] red NPS uh uh survived by real user
[00:18:44] feedback or something like that. And um
[00:18:47] and so it like looks very realistic uh
[00:18:49] of course because of the Sora video. And
[00:18:51] then I had the whole copy on like how
[00:18:53] like MPS never worked and and why uh you
[00:18:56] know user feedback is is a much better
[00:18:59] way of
[00:18:59] >> Oh, that's learning. Yeah.
[00:19:01] >> Yeah. Maybe I should make some sor
[00:19:02] videos for some meme memes like that.
[00:19:04] That's good. Some PM memes. Yeah.
[00:19:07] >> So that's that was a really good one.
[00:19:08] And then the other thing I like the
[00:19:10] thing I use every day is um I use the
[00:19:12] chat atlas uh browser. And so that I use
[00:19:17] for like writing everything,
[00:19:19] summarizing,
[00:19:20] you know, interacting with my mailbox. I
[00:19:22] use agent mode quite a bit. So just like
[00:19:24] lots and lots of different use cases
[00:19:26] where I feel like I've just gotten like
[00:19:28] 100% more effective in my in my work
[00:19:31] because I now have this.
[00:19:33] >> Maybe you can show some of that because
[00:19:34] uh when I try Okay, to be fair, I only
[00:19:36] tried Alice for like 10 minutes, but
[00:19:38] [laughter]
[00:19:38] but when I tried it, I was like, what?
[00:19:40] This is just like you know this is just
[00:19:41] like prompting chatgbt in the browser
[00:19:43] URL but like maybe you can show me some
[00:19:45] like cool use cases.
[00:19:46] >> So one kind of thing is like I may just
[00:19:49] kind of just like do something as simple
[00:19:51] as like do I have any emails I need to
[00:19:56] respond to today.
[00:19:57] >> Mhm.
[00:19:58] >> And it will like review my mailbox and
[00:20:00] identify anything that's like urgent to
[00:20:03] respond to today. So yes it like triages
[00:20:06] it pulls out what needs to be responded
[00:20:08] to. nice to have uh just like FYI emails
[00:20:12] that aren't really necessary. And then
[00:20:14] so then I can kind of just like go to
[00:20:16] one of my emails and let's pull up
[00:20:19] something that's like clearly not
[00:20:21] necessarily something I would want to
[00:20:23] actually respond to, but let's let's do
[00:20:24] it just for the sake of it. Um and
[00:20:27] respond to this email. It politely
[00:20:30] rejects.
[00:20:31] >> Okay, I see.
[00:20:32] >> Awesome.
[00:20:34] No m dashes. [laughter]
[00:20:37] >> Yeah, maybe. Yeah. Got it.
[00:20:38] >> Yeah. And so I think you know like this
[00:20:41] um this is great. So like we'll we'll
[00:20:42] write my email. I could do that and I
[00:20:44] can probably like I I can also just like
[00:20:47] do this with agent mode and do this at
[00:20:49] scale with a bunch of emails and just
[00:20:50] have it go through and write emails that
[00:20:52] are just like responses to people and
[00:20:55] then I can go through later and review
[00:20:57] them and send them off. But what I found
[00:20:59] this to be really really helpful is if I
[00:21:01] have emails that are like, you know,
[00:21:03] like are super emotional, like things I
[00:21:05] don't actually want to read, that's
[00:21:06] going to be just like annoying. Some
[00:21:09] someone got too emotional for for some
[00:21:10] reason that's like not appropriate. Um,
[00:21:13] then I can just like have chat GPT
[00:21:16] summarize the email in like three
[00:21:19] bullets so I know the the substance of
[00:21:20] it. I don't actually have to read
[00:21:22] someone like overreacting on something.
[00:21:24] And then I can like respond to the
[00:21:26] content and ask and then and then and
[00:21:28] then ask chat if you need to politely
[00:21:30] respond. And then it will usually
[00:21:31] include things like um you know I hear
[00:21:33] you or like you know I really appreciate
[00:21:35] your perspective. Like it will do the
[00:21:37] things that you need to do without like
[00:21:39] the emotional overload which is really
[00:21:41] really great.
[00:21:42] >> Interesting. [laughter]
[00:21:43] You get you get those kind of emails. Is
[00:21:44] it like when you move too fast and ship
[00:21:46] something and somebody's like what? You
[00:21:47] didn't check this box. Is [laughter]
[00:21:48] that is that what happens? Uh we had we
[00:21:50] had a lot of customers that really
[00:21:52] really wanted craft to come out as
[00:21:54] quickly as possible. So that was that
[00:21:56] that was a good use case where it was
[00:21:58] just like I just cannot I can't I can't
[00:22:00] have everyone's emotions right now. I'm
[00:22:02] just like trying to ship this product as
[00:22:04] quickly as possible but I do want to
[00:22:05] engage with everyone and feel like I'm
[00:22:07] really you know.
[00:22:08] >> Got it.
[00:22:09] >> So that's a good example.
[00:22:11] >> Got it. Okay. That that makes sense.
[00:22:12] Okay. Uh okay. Got it. And and like you
[00:22:15] can probably uh I think you also use
[00:22:17] like agent mode to like unsubscribe to
[00:22:19] spam or stuff like that. I don't ever
[00:22:20] try that stuff. Yeah.
[00:22:21] >> Yeah. Exactly. You can do that. And I
[00:22:23] think like the one one thing that is
[00:22:25] like one of my favorite things is to
[00:22:27] interact with things in line. So once
[00:22:29] you have written something you can be
[00:22:31] like is this clear and well written?
[00:22:36] >> If I actually did want to write
[00:22:37] something myself which I sometimes do.
[00:22:40] Uh then we can do that and we can kind
[00:22:42] of just like um you know update or
[00:22:45] replace this copy with whatever it does.
[00:22:47] Yeah.
[00:22:48] >> Yeah.
[00:22:49] >> There's there's a lot of different ways.
[00:22:51] >> It it's funny whenever I get my guests
[00:22:52] to do this demos like they always try to
[00:22:54] fix their spell spelling mistakes but I
[00:22:56] don't think chat cares about your
[00:22:58] spelling mistakes. It doesn't matter you
[00:23:00] know that they understands like all the
[00:23:02] spelling.
[00:23:02] >> That's true. Yes. Yeah. Yeah. Yeah. And
[00:23:04] the thing is, I bet I bet this is true
[00:23:06] for all of your guests because uh it's
[00:23:08] certainly true for me. Folks who are
[00:23:10] just like use AI a lot have a lot of
[00:23:12] spelling mistakes because the more you
[00:23:13] use AI, the less the less good you
[00:23:15] become at spelling.
[00:23:17] >> Yeah.
[00:23:17] >> And so I don't I don't normally like
[00:23:19] correct my spelling when I'm chatting
[00:23:21] with Chachi Pat, but on a podcast I feel
[00:23:23] like I actually have to like correct
[00:23:25] myself.
[00:23:25] >> Yeah. I feel like I kind of worry that
[00:23:27] my like um because I I I think I'm a
[00:23:29] pretty good writer overall, but I've got
[00:23:31] like a super lazy. I just like dictate
[00:23:33] to AI and like and I'm like hey you know
[00:23:35] can you cut this copy by 20%. Or like
[00:23:38] [laughter]
[00:23:38] and and if you if you ask me to write
[00:23:40] something from scratch again like I
[00:23:42] don't know if I can do it or not.
[00:23:43] [laughter]
[00:23:43] >> I absolutely I think you know I use the
[00:23:46] the other piece I use a lot is um I use
[00:23:48] the voice mode here a lot because and I
[00:23:50] just dictate things. I have a
[00:23:53] eight-month-old. So whenever whenever
[00:23:54] I'm like with with her um this is just
[00:23:57] such a handy thing like you can get
[00:23:59] through so many things that I wouldn't
[00:24:00] be able to because now I'm like handsree
[00:24:02] and and but yeah absolutely right. I
[00:24:04] also as a result I cannot type and I
[00:24:07] cannot spell
[00:24:08] >> there's so many things that like
[00:24:10] >> I'm outsourcing all of that to AI.
[00:24:12] [laughter]
[00:24:13] >> The only thing I can do is like uh order
[00:24:14] my little chaty between turn around like
[00:24:16] hey do this and do that.
[00:24:18] >> Yes. Yes. Which is
[00:24:19] >> Yeah. [laughter] Yeah. It was great.
[00:24:21] That's great. Yeah. Okay, let's talk
[00:24:23] about this. You know, we all love AI,
[00:24:25] but like what is something that you
[00:24:26] still do manually like that AI is not
[00:24:29] good at yet?
[00:24:30] >> Yeah, great great question. I think that
[00:24:33] um one thing uh that to me I I've seen
[00:24:37] this I've seen this show up in a few
[00:24:38] different ways, but um prompt
[00:24:40] engineering and writing evals is not
[00:24:43] something that AI can do well at all
[00:24:46] yet.
[00:24:47] >> And I thought that was it was kind of
[00:24:49] interesting. There's some controversy
[00:24:50] around this because which I didn't think
[00:24:52] so because I every time a new model
[00:24:53] comes out I try to have it do all the
[00:24:55] things including prompt engineer and I
[00:24:57] always sort of like okay not not this
[00:24:59] one not this one you know maybe next
[00:25:01] one. Um, and then when uh GPT5 came out
[00:25:05] and I was reading the OpenAI prompt
[00:25:08] engineering guide for GPT5, they do have
[00:25:11] a suggestion in there that you should
[00:25:13] use GPT5 to like refine your prompts.
[00:25:16] >> And um or maybe that was in the eval
[00:25:19] guide. It was in one of the guides. Um
[00:25:21] and so I ended up trying that again and
[00:25:26] I found that actually the prompt I got
[00:25:29] was workable. like it was it was like
[00:25:31] finally it could do some things like it
[00:25:33] could actually write prompts but it was
[00:25:35] sort of still like a step worse than the
[00:25:38] human written prompts. So I would have
[00:25:41] this prompt that I used specifically for
[00:25:43] one step in our analysis pipeline where
[00:25:45] we use GPT4.1
[00:25:47] um like a non-reasoning model for speed
[00:25:50] um because we just can't have it go go
[00:25:52] and start reasoning and um in that
[00:25:55] prompt I could get something that worked
[00:25:58] as well as that prompt but only with
[00:26:00] GPT5. So GPT5 could write a good enough
[00:26:03] prompt that could work as well as a
[00:26:05] human written prompt for GPT4.1 but only
[00:26:08] with GPT5. So still wor clearly worse
[00:26:10] but but it was getting there like it was
[00:26:13] getting closer to it and you know one
[00:26:15] thing I've sort of like learned that
[00:26:18] there folks use AI a lot for writing
[00:26:20] prompts which is not a great idea but I
[00:26:22] think particularly engineers tend to do
[00:26:24] it because they use cursor for a lot of
[00:26:26] things and so as a result they also use
[00:26:28] cursor to write prompts and and
[00:26:30] oftentimes end up using actually much
[00:26:33] worse models in GPT5 or writing prompts
[00:26:35] um and they absolutely cannot do it like
[00:26:37] it's not a good idea
[00:26:39] And when you say writing prompts, you
[00:26:40] mean like uh like writing from scratch
[00:26:42] or like editing a prompt that you have?
[00:26:45] >> Both. Can't do either.
[00:26:46] >> Interesting.
[00:26:47] >> Well, yes.
[00:26:48] >> Like for my little creator prompts,
[00:26:50] sometimes I have a back and forth
[00:26:51] dialogue with it and then like make a
[00:26:54] bunch of changes and then at the end
[00:26:55] I'll be like, "Hey, can you go update
[00:26:57] the original prompt to include all this
[00:26:59] feedback?"
[00:27:00] >> Yeah.
[00:27:00] >> And then it it does do that. I I I do
[00:27:02] have to manually review it to make sure
[00:27:04] it's actually good.
[00:27:05] >> Yes. But I I guess that kind of saves me
[00:27:06] some time, you know.
[00:27:08] >> Yes. Well, yeah. So, I do that too. And
[00:27:10] what I found is like usually um then
[00:27:13] when I write when when I when I then run
[00:27:15] evals on like different components of
[00:27:18] it, it's kind of like maybe like 10% of
[00:27:21] the improvements worked and they still
[00:27:23] had to be tweaked by human.
[00:27:25] >> Um and 90% made it actually worse. So
[00:27:28] you kind of you can't you can't just
[00:27:30] take like the AI generated improvement
[00:27:33] to the prompt and just run with it. I
[00:27:35] would say you know like there's like a
[00:27:36] lot of work that massaging but sometimes
[00:27:39] yeah it could propose something that
[00:27:40] could actually work but you still need
[00:27:42] to do lots of work to it to to make it
[00:27:44] actually perform better.
[00:27:46] >> Interesting. Okay. Yeah. I I I guess it
[00:27:48] is kind of like an intern. You got to
[00:27:49] supervise it. You got to supervise what
[00:27:51] it does.
[00:27:51] >> Yes. That's right.
[00:27:52] >> Yeah.
[00:27:53] >> It's getting there. Eventually, we will
[00:27:55] be like the interns for it, you know,
[00:27:57] but
[00:27:57] >> Yeah. Yeah.
[00:27:58] >> But we're not there yet.
[00:27:59] >> I I feel like I'm going to be a much
[00:28:01] lazier intern than AI, so I don't know
[00:28:03] how it's going to work out. [laughter]
[00:28:05] >> Me, too. I will be fired immediately.
[00:28:07] >> Yeah. Okay. Uh Okay, cool. Well, let's
[00:28:11] talk about let's talk about Amplitude
[00:28:12] now, actually. Yeah. So, so you just
[00:28:14] shipped a big update. You know, one
[00:28:17] thing I feel about uh Amplitude and any
[00:28:19] kind of data product is is that um you
[00:28:22] can't just have the data like just
[00:28:24] having the quantitive stuff doesn't give
[00:28:25] you the full picture. Like you got to
[00:28:27] have the user feedback and the
[00:28:28] qualitative stuff. It's it's kind of
[00:28:30] like what Jeff Bezos said, right? Like
[00:28:31] if the data doesn't match the anides,
[00:28:33] like you should trust the anides.
[00:28:35] [laughter]
[00:28:35] >> Yes, I can.
[00:28:37] >> So I'm I'm I'm really glad that you
[00:28:38] actually shipped the the quality stuff
[00:28:40] as part of M2. I think that's a huge
[00:28:41] gap. So So do you want do you want to
[00:28:43] actually show this product that they
[00:28:44] love?
[00:28:44] >> Yeah, absolutely. And I and I completely
[00:28:46] agree. Obviously I will agree because
[00:28:48] you know that was that was my baby. So
[00:28:51] what I what I ended up shipping was is
[00:28:53] like we we've been integrating craft
[00:28:55] into amplitude and so uh amplitude
[00:28:58] feedback is essentially craftful in in
[00:29:00] amplitude and uh but what is different
[00:29:03] and I will show you is how we've
[00:29:05] integrated it to show both quant and
[00:29:08] quall in one place because obviously
[00:29:09] craffle was only quall. Um so at at a
[00:29:13] high level sort of what what it does is
[00:29:16] um you you start from just connecting
[00:29:18] your sources of feedback and so you can
[00:29:20] connect support ticket sources or public
[00:29:23] data like app reviews or Google play and
[00:29:26] I think one one thing that's that's that
[00:29:29] customers are reacting to quite a bit is
[00:29:31] just like how easy it is to connect
[00:29:33] things like if you if you wanted to
[00:29:34] connect app review all you you kind of
[00:29:37] like enter enter your the name of your
[00:29:39] app and then it just pulls off and
[00:29:40] collects it. It collects that data every
[00:29:43] day and then um and then it gives you
[00:29:45] these prioritized lists. Um so you get
[00:29:47] like your list of feature requests, top
[00:29:49] feature requests from across these
[00:29:51] different sources. In this case, I have
[00:29:53] connected a bunch of like public data
[00:29:55] about Slack. So you have like um iOS and
[00:29:59] Android reviews for the Slack app,
[00:30:01] YouTube reviews for Slack, uh and I
[00:30:04] think they also have like Twitter Slack
[00:30:06] Slack mentions. And so uh what you get
[00:30:09] is this like list of here's their top
[00:30:11] feature requests, the top feature
[00:30:13] request that was mentioned 242 times
[00:30:16] across all the different sources as
[00:30:17] notification preferences and controls.
[00:30:19] So you can click into that and see the
[00:30:21] actual like what did users say about
[00:30:23] that? And then you can look at these
[00:30:25] like deep dives that tell you within
[00:30:27] those 242 what were the common topics
[00:30:30] and use them as as filters um to look at
[00:30:33] that. Um the and and you can do the same
[00:30:37] thing with like uh like you can look at
[00:30:40] top complaints um in the product uh
[00:30:44] which of course is again too many
[00:30:45] notifications but then pricing and uh
[00:30:48] communication things like that. You can
[00:30:50] look at um to the contrary like what
[00:30:53] what are some things people actually
[00:30:54] like about the product? Um and that's
[00:30:57] usually helpful for like strategic
[00:30:58] planning to see like what what should we
[00:31:00] double down on. Um yeah,
[00:31:02] >> or like what brands came up frequently.
[00:31:05] That's usually helpful to see how do um
[00:31:08] how do my customers talk about my
[00:31:09] competitors? That's often what comes up.
[00:31:11] Maybe there's like some big integrations
[00:31:12] that also also show up there. But then
[00:31:14] the like to go back to um feature
[00:31:18] request. The cool thing is that because
[00:31:20] this now is an amplitude, we can take
[00:31:23] these 242 users and create a cohort and
[00:31:28] um look at how these users are using the
[00:31:31] product or look at related session
[00:31:33] replays of like how users are
[00:31:35] interacting with their notifications and
[00:31:37] and see both kind of what they did and
[00:31:40] what they're saying in one place. or we
[00:31:42] can create a survey and ask more
[00:31:44] questions about notifications and then
[00:31:47] that data will feed back into AI
[00:31:49] feedback and and be analyzed alongside
[00:31:51] of this. So it kind of like makes your
[00:31:53] your feedback richer and richer. And
[00:31:55] then there's like a few other
[00:31:56] >> Yeah.
[00:31:56] >> Uhhuh.
[00:31:57] >> Yeah. So that's those are kind of like
[00:31:58] the new the new parts. So like what what
[00:32:01] we didn't have in craft what we now
[00:32:03] we're able to do in amplitude because we
[00:32:04] have both pieces in in one place. Yeah.
[00:32:07] And then of obviously like sometimes
[00:32:09] you'll just want to see like what are
[00:32:10] people saying on Twitter um and or what
[00:32:13] what are people saying like for my iOS
[00:32:15] app and so you can filter it in
[00:32:17] different ways or like look at the first
[00:32:19] last day if you have
[00:32:20] >> I think um I I I I think combining that
[00:32:23] feedback with the metrics is actually
[00:32:25] pretty it's actually pretty amaz I don't
[00:32:27] I don't think there's another product
[00:32:28] that does this right is there I don't
[00:32:30] think no I don't think there is
[00:32:32] >> yes there isn't there isn't we're the
[00:32:33] first we got we got to do the first
[00:32:35] because it's sort of like I mean It's
[00:32:37] it's a cool like that's that's
[00:32:38] essentially sort of like the the the
[00:32:40] biggest reason behind the the
[00:32:42] acquisition is to be able to bring this
[00:32:43] all together in one place and really
[00:32:45] paint that whole picture. Uh which is
[00:32:47] really really cool.
[00:32:48] >> Um
[00:32:48] >> that's awesome too. So I can make a
[00:32:49] cohort from any of these uh users and
[00:32:52] then I can look at all the
[00:32:53] >> funnel metrics or whatever I want to
[00:32:55] look at for that.
[00:32:56] >> Yeah. Exactly. Exactly. And study how
[00:32:58] they're doing. Like you can look you
[00:33:00] could set up Yeah. You set up a funnel
[00:33:01] for for notifications uh notification
[00:33:04] management and and and look at that. Um
[00:33:06] and yeah and and so and so like then
[00:33:08] some some other ways you can interact
[00:33:10] with this is that maybe you want to ask
[00:33:13] some very like specific questions like
[00:33:16] uh you may want to like the thing is
[00:33:18] probably what we have because it's Slack
[00:33:20] and we we all use it. We know that
[00:33:22] there's a bunch of things about
[00:33:24] notifications from across like different
[00:33:26] things both feature requests and
[00:33:28] complaints and uh various topics. But
[00:33:30] like uh we could also ask what do users
[00:33:34] say about notifications.
[00:33:36] >> Mhm.
[00:33:37] >> So it's going to pull up all of that
[00:33:38] feedback and give us a summary of like
[00:33:41] what what users are doing with
[00:33:42] notifications. But then you can actually
[00:33:44] take it one step further and say like
[00:33:46] take you using all this data about
[00:33:48] notifications. Now write a PRD for me
[00:33:51] based on all this data. And then it will
[00:33:53] write a PRD that you can go ahead and um
[00:33:57] and like edit in the product. Oh, there
[00:33:59] it is. Okay. So yeah, so you can see
[00:34:01] kind of like critical issues, usability,
[00:34:02] frustrations, and then some positive
[00:34:04] notes. Um, so there's and then and then
[00:34:07] you can kind of like act on it and and
[00:34:09] do more.
[00:34:09] >> That's great.
[00:34:10] >> Yeah. So there's a few a few different
[00:34:11] ways to interact with this. Um, the what
[00:34:13] I just demoed is actually in our MCP. So
[00:34:16] you can do this in Amplitude, but you
[00:34:18] can also just do it in in in Cloud or or
[00:34:21] Chat GBT and um and pull in that data in
[00:34:24] other places or like schedule uh
[00:34:26] notifications using agents and things
[00:34:28] like that. So it's pretty there's kind
[00:34:29] of more things you can do with it beyond
[00:34:31] kind of what what automatically happen.
[00:34:33] >> Okay. So I guess this like saves a bunch
[00:34:35] of time uh like okay number one saves
[00:34:38] time manually copy and pasting feedback
[00:34:40] to get AI to summarize stuff like this
[00:34:42] is all done for you already.
[00:34:44] >> Yes.
[00:34:44] >> Yeah.
[00:34:45] >> Uh trying to classify into different uh
[00:34:47] categories that's done for you too.
[00:34:49] >> Yes.
[00:34:49] >> Um and then and then yeah even the PRD
[00:34:52] step you just have to get the cross
[00:34:54] functional alignment step done then then
[00:34:56] it's the perfect product.
[00:34:57] >> Yeah. Yeah. Yeah, we just need Exactly.
[00:34:58] We just need to replace all those humans
[00:35:00] with other AIS and then it's going to be
[00:35:02] so great.
[00:35:03] >> This cross functional alignment. Yeah.
[00:35:06] Like like a cross likelihood of getting
[00:35:08] cross functional alignment score or
[00:35:10] something. No, no, I'm just joking. I'm
[00:35:11] just joking. Yeah,
[00:35:12] >> that would be great. That would be
[00:35:14] awesome. Yeah. And then so so the and
[00:35:17] the cool thing is that it does gather
[00:35:18] all this data every day. So you can
[00:35:21] filter it by just like the last day and
[00:35:22] look at what did people say based on my
[00:35:24] last launch or what did people say
[00:35:26] >> in the past few weeks when you're doing
[00:35:28] sprint planning or like quarterly
[00:35:29] planning. So really like it pulls the
[00:35:32] data daily and it updates your list uh
[00:35:35] based on what's now showing up in the
[00:35:36] data.
[00:35:37] >> Yeah. I I I can see a lot of potential
[00:35:39] to expand this too. Like I I feel like
[00:35:40] maybe eventually it can even do replies
[00:35:44] to the customers or something.
[00:35:45] >> Yes. You know.
[00:35:46] >> Yeah. Yeah. Yeah. Yeah. We we had that
[00:35:48] on our road map at Craft. So it's now
[00:35:50] it's now come come over to Ampatitude on
[00:35:52] our migrated roadmap.
[00:35:54] >> Okay.
[00:35:54] >> Definitely definitely want to be able to
[00:35:56] close the loop with customers.
[00:35:58] >> It and it it is so easy, right? Because
[00:36:00] you you're really you're getting these
[00:36:01] like uh we know like the 200 users that
[00:36:05] have requested this. So it it becomes
[00:36:08] really really easy to close the loop.
[00:36:09] 242. Like I built a much simpler version
[00:36:12] of this too. Uh sunrising feedback and
[00:36:15] um yeah I I feel like AI is actually
[00:36:18] even arguably even better for the
[00:36:20] qualitative use case than like the quant
[00:36:22] stuff
[00:36:23] >> because the quality of stuff like you
[00:36:25] know there's like a lot of copy like
[00:36:27] it's really good at summarizing copy and
[00:36:28] like extracting trends and stuff and
[00:36:30] insights
[00:36:31] >> and and the the numbers is is like it's
[00:36:34] not really good at math, right? It's
[00:36:35] not.
[00:36:36] >> No. [laughter]
[00:36:37] Well, it's getting better. It's it's
[00:36:38] getting much better at math. But you're
[00:36:40] absolutely right. It got better at
[00:36:41] summarization before it got better at
[00:36:43] math. You know, I think for me having
[00:36:45] having built like the first prototype of
[00:36:48] this like in early 2020 uh and been and
[00:36:52] seeing the evolution of LLMs from like
[00:36:54] from the early days, it was terrible at
[00:36:57] text summarization back then. It was
[00:36:59] really good at text generation, but it
[00:37:01] was terrible at text summarization. And
[00:37:03] so eventually this was sort of like an
[00:37:06] unlock that that came I would say sort
[00:37:08] of like
[00:37:09] >> probably like early early 2023 late 2022
[00:37:13] I say probably the Vinci model like
[00:37:16] right before the the the GPT 3.5 which
[00:37:18] is like the chat GPT the original Chat
[00:37:20] GPT model that's when summarization use
[00:37:23] cases started really working somewhat it
[00:37:27] was still really really hard you had to
[00:37:28] do a ton of prompt engineering to to get
[00:37:30] it to do something and so math I feel
[00:37:32] like we're just we're just at the cusp
[00:37:34] of like it actually getting better at
[00:37:36] math or it's actually getting better.
[00:37:37] Like coding was like probably like last
[00:37:39] year was when all the coding use cases
[00:37:42] started to get unlocked. It's just like
[00:37:43] we're just seeing this like we're on
[00:37:44] this path of model capability going from
[00:37:48] AI not working at all to like AGI. So we
[00:37:52] will like with every new model that
[00:37:54] comes out there's always like this
[00:37:55] capability unlock which is really cool
[00:37:57] to see. Yeah, that's actually good
[00:37:59] because my my last question for you was
[00:38:00] going to be about like you know why
[00:38:02] haven't we seen like you know like a $29
[00:38:03] billion AI analyst company yet or or
[00:38:06] something or maybe [laughter]
[00:38:07] we have but but like
[00:38:09] >> but but maybe the answer is just like
[00:38:11] you know the model if the models catch
[00:38:12] up then like you know it will just
[00:38:14] unlock a whole bunch more use cases
[00:38:16] >> for exactly I I think that's exactly it
[00:38:19] I think I mean I think that's half of
[00:38:20] the half of the answer is that that it's
[00:38:23] been like the the the models that we'll
[00:38:26] be able to new AI analytics really have
[00:38:29] just started to come out like the I
[00:38:31] think that that those use cases are just
[00:38:33] starting to get unlocked like this is
[00:38:34] the time to build that um and we're
[00:38:37] starting to see that more and more like
[00:38:38] the stuff we're building now that of
[00:38:40] amplitude things are just starting to
[00:38:42] work in ways that I just know that like
[00:38:44] a year ago certainly couldn't have
[00:38:45] worked um but that I think that's part
[00:38:48] of the problem I think the other piece
[00:38:50] of the problem is user adoption uh
[00:38:52] because the persona that tends to use
[00:38:55] analytics has built up a lot of
[00:38:57] workflows around that in a certain way.
[00:39:00] That's harder to replace and harder to
[00:39:02] like change those those workflows than
[00:39:04] it is to replace a workflow that just
[00:39:06] has to deal with like document editing
[00:39:08] or you know like writing copy or
[00:39:10] something like that. That's just like so
[00:39:11] much so much easier. Like it's like
[00:39:13] workflows where folks are like writing
[00:39:15] blog posts or something like that's just
[00:39:17] like such an easy thing to to come and
[00:39:19] replace whereas folks have like built up
[00:39:20] so much context around how they're doing
[00:39:23] their data analysis. M
[00:39:25] >> I think that that's a much harder like
[00:39:26] user adoption problem that again we're
[00:39:28] starting to see that with like early AI
[00:39:30] adopters within those spaces are
[00:39:32] starting to try to think about how would
[00:39:34] I use AI for this but I think it's just
[00:39:36] like it is it is a more difficult puzzle
[00:39:38] to get get adoption there.
[00:39:40] >> I feel like a lot of data scientists get
[00:39:42] asked by their annoying PMs like hey
[00:39:44] what about this data or what about that
[00:39:45] data or can do can you run this query
[00:39:47] and and like I feel like that kind of
[00:39:49] stuff hopefully can get automated first
[00:39:51] so that they can
[00:39:51] >> yes
[00:39:52] >> do more interesting work. Totally.
[00:39:54] Totally. Yes. Yeah. Exactly. So yes, so
[00:39:56] that's a but I think like for it to be a
[00:40:00] really big solution, it needs to be able
[00:40:02] to do all those things and for all those
[00:40:04] people. Um so that's that's partly like
[00:40:06] you know why why why not like that
[00:40:08] really big like uh uh disruption hasn't
[00:40:12] happened. I think that that's that's the
[00:40:14] reason.
[00:40:14] >> Yeah. And and also another reason I
[00:40:16] think is like you know just like you
[00:40:18] can't get the data wrong, right? Like
[00:40:20] you can't really have too much on day
[00:40:22] data. You got to get the data correct
[00:40:23] like almost 100% of the time.
[00:40:25] >> Yeah. [laughter] Yeah. Exactly. Exactly.
[00:40:26] No, the the quality bar is super super
[00:40:28] high. It's really really important that
[00:40:30] it's actually correct. Like you can't be
[00:40:32] like, "Oh, you know, we had uh like I
[00:40:34] don't know your your daily active users
[00:40:36] were off by just a few digits, but
[00:40:39] didn't really matter, right?
[00:40:41] >> Like it's so important."
[00:40:41] >> Yeah. It's it's like the AI companies
[00:40:43] claiming they have 100 million AR. Maybe
[00:40:44] Oh, it's actually 10 million AR, not
[00:40:46] >> Yeah. Yeah. Exactly. Exactly.
[00:40:48] >> Yeah. Yeah. Um
[00:40:49] >> they're probably just using AI. It's not
[00:40:51] their fault. Yeah. It's not their fault.
[00:40:52] It's not their fault. Yeah. [laughter]
[00:40:54] Okay, cool. All right. Well, Jana, I
[00:40:56] mean, you're really busy, but uh where
[00:40:57] can people find you and your product?
[00:41:00] >> Yeah, mostly right now we we we've gone
[00:41:02] all AI native and we're on Twitter all
[00:41:05] the time. Um and so, um you can follow
[00:41:08] along Amplitude HQ on Twitter. Um and
[00:41:11] then I am I'm there as tweets. I need to
[00:41:14] update my handle to be like Jana X, but
[00:41:16] I sound so bad.
[00:41:18] >> So, I wouldn't do that. And yeah, we're
[00:41:20] all now trying to be on on Twitter quite
[00:41:23] a bit. Our um founder CEO Spencer Skates
[00:41:26] is on Twitter. You can follow him along.
[00:41:28] Um he's just Spencer Skates is the
[00:41:30] handle.
[00:41:31] >> Yeah, I heard he really wants more
[00:41:32] followers. So maybe uh everyone watching
[00:41:34] this
[00:41:35] >> should go follow follow him and say this
[00:41:38] episode.
[00:41:39] >> Yeah, then then he'll compliment Yana
[00:41:41] for for sure. Yeah. [laughter]
[00:41:43] >> Cool.
[00:41:43] >> Love it. Thanks, Skater. This is like
[00:41:45] it's exactly what I needed.
[00:41:47] >> Okay, cool. All right. Well, thanks so
[00:41:49] much for your time. This is awesome
[00:41:50] conversation.
[00:41:51] >> Really really enjoyed it.
