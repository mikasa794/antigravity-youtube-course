[00:00:05] Hi listeners, welcome to No Priors. How
[00:00:08] can we even begin to wrap this year up?
[00:00:10] The AI field has grown, breaking out
[00:00:12] into the mainstream and taking center
[00:00:14] stage with policy makers. Chat GPT
[00:00:16] shipped massive numbers and asked for
[00:00:18] massive [music] dollars. Gemini and
[00:00:20] Google roared back strong. And on the
[00:00:22] application front, AI coding has shifted
[00:00:24] to agents and is eating up all of our
[00:00:26] inference capacity. Doctors are adopting
[00:00:29] clinical decision support on mass and in
[00:00:31] law and customer support. Enterprise
[00:00:32] adoption is accelerating. [music] What's
[00:00:34] next? On the research front, the race
[00:00:37] has multiple live players with open
[00:00:39] source closing the gap too. [music] A
[00:00:41] handful of Neolabs, new research labs
[00:00:43] got funded this year. And the narrative
[00:00:45] is changing. Ilia is calling it the age
[00:00:48] of research. People are trying different
[00:00:50] ideas around diffusion,
[00:00:52] self-improvement, data efficiency, EQ,
[00:00:55] large scale Asian collaboration,
[00:00:57] continual learning, energy transformers.
[00:01:00] It's more open than it's ever been.
[00:01:02] Finally, we had a lot of attempts to
[00:01:04] make AI reach into the real world with
[00:01:06] renewed optimism around robotics. Next
[00:01:09] year, those companies are going to start
[00:01:11] making contact with reality. From a
[00:01:13] prediction standpoint, personally, I
[00:01:15] think we're going to see somebody make a
[00:01:17] lot of money. Hundreds of millions of
[00:01:18] dollars trading markets with LLMs next
[00:01:20] year. It's inevitable. So, we're in the
[00:01:23] second or third inning. Markets are
[00:01:25] running a little hot and a little
[00:01:26] volatile. It's hot in the hot tub. So,
[00:01:28] get into it with me and Alad. Okay.
[00:01:30] Alad, it's been a year.
[00:01:31] >> I know. How's it going? 2026, baby.
[00:01:34] >> Are you feeling the AGI? Are you feeling
[00:01:36] AI AI winter in a good way?
[00:01:39] >> I think I'm actually just feeling
[00:01:40] microplastics. I think I'm now 80%
[00:01:42] microplastics and just increasing my
[00:01:44] microplastic consumptions. A friend of
[00:01:46] mine actually launched a new water brand
[00:01:48] that uh has no microplastics by the way.
[00:01:50] It's called Loop and they have like
[00:01:51] glass bottles and also the cap doesn't
[00:01:53] have plastic.
[00:01:54] >> Does it come with continual testing?
[00:01:55] >> Yeah, that's continual testing for you.
[00:01:58] >> They did actually try to take out all
[00:01:59] the microplastics and so they uh I guess
[00:02:01] bottled water in actual bottles has more
[00:02:04] microplastics than plastic bottles
[00:02:05] because of the cap.
[00:02:06] >> Okay, we'll check back in with you in 27
[00:02:09] to see if you feel
[00:02:10] >> Yeah. But I'm just completely oified out
[00:02:12] of plastic. I'm actually really worried
[00:02:14] about microlastics. What about all the
[00:02:16] little glass particles? Aren't you
[00:02:17] worried about that? People talk about
[00:02:19] microlastics, but not microlastics. I'm
[00:02:21] much more concerned about that.
[00:02:22] >> I don't think those particles end up
[00:02:24] embedded for you permanently.
[00:02:26] >> Silicon. [laughter]
[00:02:28] You're not worried about silicons. When
[00:02:30] I go to the beach, I'm like, "Oh no,
[00:02:32] microlastics everywhere." I'm actually
[00:02:34] very willing to insert silicon in my
[00:02:36] body eventually in my [laughter]
[00:02:39] >> Wow, that was Yeah, I'm not gonna say
[00:02:41] anything. We can keep going.
[00:02:43] >> What's What's happening in AI? Al, what
[00:02:45] are you where where are we and what are
[00:02:46] you most excited about?
[00:02:47] >> Yeah, I guess for 26 there's a bunch of
[00:02:49] stuff I think will be interesting that's
[00:02:51] coming. I think we will um I think
[00:02:54] there's probably four or five things.
[00:02:55] One is I think people will proclaim yet
[00:02:56] again that AI is not doing much and it's
[00:03:00] overhyped and like that MIT report that
[00:03:02] people are quoting that I thought really
[00:03:03] didn't matter and the reality of the
[00:03:05] technology ways to take like 10 years to
[00:03:06] propagate and people are getting
[00:03:08] enormous value out of AI already and
[00:03:10] they're going to get way more out of it
[00:03:10] in the future. You know, so there's
[00:03:12] these undoubtedly next year there'll be
[00:03:14] these overstated but bubble claims as
[00:03:16] well as um hey I actually isn't working
[00:03:19] that well kind of claims and that
[00:03:20] happens every technology cycle and we'll
[00:03:21] just hear it again next year and
[00:03:23] there'll be pundits and discussions and
[00:03:25] just a bunch of waste of time on it. So
[00:03:26] I think that'll happen. I think another
[00:03:28] prediction for 26 is the next set of
[00:03:31] verticals will hit massive scale. I
[00:03:32] think this year we saw consolidation of
[00:03:34] coding into a handful of players, of
[00:03:36] medical scribing into a handful of
[00:03:38] players, of legal into a handful of
[00:03:40] players like Harvey and others. And so I
[00:03:42] think we'll see that next set of
[00:03:43] consolidated verticals happening. So
[00:03:45] that'll be interesting. I can keep
[00:03:47] going. I have like a bunch of these. Do
[00:03:48] you want to go next? We can alternate. I
[00:03:50] just did two. Why don't you do two?
[00:03:51] >> Maybe I'll react.
[00:03:52] >> Or react.
[00:03:53] >> I'll react and then I'll and then I'll
[00:03:55] give you two predictions. Um I have to
[00:03:57] think of my predictions while I'm
[00:03:58] reacting. So I'm glad I have at least
[00:03:59] two threads. Yes. I I think that the
[00:04:02] overall sentiment on AI in the investing
[00:04:07] landscape is a lot of people getting
[00:04:10] stressed about the amount of capital
[00:04:12] they have at work and then just a level
[00:04:15] of uncertainty around uh the adoption
[00:04:19] cycle and technical bets that people are
[00:04:21] making that they don't have full first
[00:04:23] principles confidence on coming to
[00:04:24] roost. So, uh I I think like any number
[00:04:27] of exogenous factors plus noise about um
[00:04:32] the speed of adoption, which by the way
[00:04:34] seems like blinding overall and we can
[00:04:36] talk about what the constraints are.
[00:04:37] >> Yeah. So fast I don't even know what
[00:04:39] people are talking about. I I just saw a
[00:04:41] report um that talked about it's from
[00:04:43] this group called uh off call that
[00:04:46] talked about adoption of AI by doctors
[00:04:48] and look there is just amazing adoption
[00:04:52] of of course you know several different
[00:04:53] categories like documentation clinical
[00:04:56] decision support with things like a
[00:04:57] bridge and open evidence and obviously
[00:04:59] the general models but there's like
[00:05:01] massive enthusiasm from most of the
[00:05:04] physician profession here and I'm like
[00:05:06] okay of of all of the domains that were
[00:05:08] professional considered more
[00:05:10] conservative. The fact that there is
[00:05:12] this like you know desire to have things
[00:05:15] that make work better seems like
[00:05:16] obviously to continue in the other
[00:05:18] professions. I I think this is by the
[00:05:21] way super underd discussed that the
[00:05:23] people who tended to be the slowest
[00:05:25] adopters of technology love AI. That's
[00:05:28] physicians, that's lawyers, that's
[00:05:30] certain accounting types. It's, you
[00:05:32] know, it's it's actually kind of
[00:05:33] fascinating. It's compliance, you know,
[00:05:36] it's all the people who always never
[00:05:38] adopt technology are now adopting this
[00:05:39] stuff fast. So, I do think that's really
[00:05:41] notable and very under discussed.
[00:05:43] >> It will keep happening. There are
[00:05:44] actually lots of professions where like
[00:05:46] being able to reason and interact with
[00:05:48] unstructured data is very useful. Like I
[00:05:50] expect that there's going to be some
[00:05:52] like negative market current. Like you
[00:05:54] know if Nvidia doesn't overperform by
[00:05:56] some massive amount one quarter,
[00:05:58] everybody's going to freak out. But I I
[00:06:01] think that has very little to do with
[00:06:02] the fundamental secular change.
[00:06:03] >> Yeah. It has to do with microplastics
[00:06:05] and Nvidia. It's my two cents.
[00:06:06] >> It has to it has to do with um
[00:06:08] microlastics as you said.
[00:06:09] >> Yeah, it's true. Actually, the silicon
[00:06:11] there is in the air. I bet that they
[00:06:13] have microlastics all over the place.
[00:06:14] It's messed up. Sarah,
[00:06:16] >> it's part of the trade. If you make $20
[00:06:18] million as an average Nvidia employee,
[00:06:20] you also have to have microlastics in
[00:06:22] your blood.
[00:06:23] >> Don't listen to this, Jensen. Jensen's
[00:06:24] our next guest. You can't hear that.
[00:06:26] >> 1% microlastics in the blood.
[00:06:28] >> I think um you know, a third area is the
[00:06:32] next set of foundation models are going
[00:06:34] to come. And by that I don't mean the
[00:06:35] neolabs and the and the nextgen LLMs
[00:06:39] which of course will happen but I mean
[00:06:40] uh physics materials um science progress
[00:06:44] by models math progress and I think
[00:06:46] what'll happen is there'll be one or two
[00:06:47] usea one or two cases where it works
[00:06:49] really well for something they'll invent
[00:06:50] some new material or there'll be some
[00:06:52] conjecture proved or something
[00:06:55] and then it'll fall into this overstated
[00:06:57] hype cycle of it's going to change
[00:06:59] everything about physical sciences or
[00:07:00] whatever and that oneoff will be
[00:07:03] overstated And in the long run, the
[00:07:04] trend will be understated and will be
[00:07:06] incredibly important. So that's what
[00:07:07] that's another prediction for next year
[00:07:08] is there'll be a couple anecdotal
[00:07:10] one-offs in science that will make
[00:07:13] people say, "Look, science is solved."
[00:07:14] And they'll realize science has been
[00:07:15] solved and then later science will be
[00:07:17] solved.
[00:07:17] >> I have uh Okay, fine. Three three quick
[00:07:20] predictions for you. One is there's
[00:07:22] going to be like some collapse of
[00:07:25] sentiment around a set of robotics
[00:07:28] companies next year. Not because it like
[00:07:30] actually isn't as a field going to
[00:07:32] progress but because you know people are
[00:07:35] beginning to project timelines
[00:07:38] >> and uh you know not everybody is going
[00:07:40] to deliver on those timelines.
[00:07:42] >> What's your timeline? I think that we
[00:07:44] will see um humanoid and semihumanoid
[00:07:47] robots get deployed at small scale in
[00:07:50] environments be the consumer or
[00:07:52] industrial next year and not everything
[00:07:54] will work and that like the because
[00:07:57] there's this you know hype cycle around
[00:07:59] human rights overall as soon as
[00:08:01] something doesn't perfectly work which
[00:08:03] it will not people are going to freak
[00:08:04] out right and then there's going to be
[00:08:06] some bifurcation about people investing
[00:08:09] >> yeah I mean we're in year 15 17 whatever
[00:08:12] self-driving something around there and
[00:08:14] it's really working now but it
[00:08:17] seems like robotics should have maybe a
[00:08:18] faster curve but a similar curve right
[00:08:20] it's going to take some time to figure
[00:08:21] all this stuff out and then once it's
[00:08:23] figured out it's going to be really
[00:08:24] valuable and the big question for me on
[00:08:25] robotics you know it's interesting if
[00:08:26] you look at self-driving there's like
[00:08:28] two dozen three dozen whatever
[00:08:30] legitimate self-driving companies really
[00:08:31] good teams and good approaches and all
[00:08:33] the rest and then arguably the two
[00:08:35] biggest winners at least now are Whimo
[00:08:38] and Tesla which were two incumbents
[00:08:40] right Whimo's Google Tesla is Tesla So I
[00:08:42] wonder what will happen to robotics. It
[00:08:44] feels to me like Optimus or some form of
[00:08:46] like Tesla robot will be one of the
[00:08:47] winners most likely, right? High
[00:08:49] probability. And then the question is
[00:08:51] does Whimo just adopt what it's doing
[00:08:53] for cars to robots as well? Because
[00:08:55] there's some similar problems there. Is
[00:08:57] it some other big industrial company? Is
[00:08:59] it startups? Like who are who are the
[00:09:01] winners and why? And structurally when
[00:09:04] you have a lot of capital needs but also
[00:09:05] a lot of hardware and manufacturing
[00:09:07] needs that's going to favor incumbents
[00:09:10] which is self-driving right um I guess
[00:09:12] arguably the other winners in
[00:09:13] self-driving are Chinese companies right
[00:09:16] Chinese car companies which are banned
[00:09:18] from coming into the US market and those
[00:09:20] will probably also be winners in
[00:09:21] robotics right the most likely global
[00:09:23] winners in robotics will be some subset
[00:09:25] of China plus Tesla plus something else
[00:09:28] right maybe maybe one of the startups
[00:09:30] >> I think that's right but that's like I I
[00:09:32] think in most industries like
[00:09:34] >> you know the incumbents are more likely
[00:09:36] to win than the startups if you're just
[00:09:38] looking at it like as as a numbers game.
[00:09:41] >> I don't know. Yeah, I don't know. I
[00:09:42] don't think so. I think um I think
[00:09:44] there's startup industries where
[00:09:45] startups should win and there's
[00:09:46] incumbent industries where incumbents
[00:09:48] should win and they have different
[00:09:49] characteristics in terms of market
[00:09:50] structure, in terms of capital needs, in
[00:09:52] terms of certain of expertise and supply
[00:09:53] chain, you know. So I do think there are
[00:09:55] markets where incumbents should
[00:09:57] definitionally do better. They don't
[00:09:59] always but they typically do. And then I
[00:10:00] think there are markets where startups
[00:10:02] will do better.
[00:10:03] >> Sure. But I I don't I don't argue that
[00:10:05] like some markets are like the modes are
[00:10:07] structurally deeper, right?
[00:10:09] >> But one way that you might look at
[00:10:11] autonomous vehicles is it's one very
[00:10:14] complex single use case robot.
[00:10:17] >> And it mostly does locomotion. It does
[00:10:19] lots of other necessary types of
[00:10:21] prediction, defensive drive, whatever
[00:10:22] else. But it's it's it's a single use
[00:10:25] case robot.
[00:10:25] >> Yeah. And we and we forget there's a lot
[00:10:27] of good ones like that. Dishwashers are
[00:10:29] great single-use robots. Vacuum cleaners
[00:10:31] are great. You know, like there's all
[00:10:33] these things that we actually have that
[00:10:34] are robots in the home that we pretend
[00:10:35] aren't, right? We forgot that they're
[00:10:36] robots. Elevators are robots.
[00:10:38] >> No, seriously. Escalators are robots.
[00:10:40] >> I'm going to use the language of like
[00:10:42] for a robot [laughter] to be a robot, it
[00:10:44] has to be somewhat intelligent, right?
[00:10:46] Um and so dishwasher doesn't count as an
[00:10:48] appliance. Um a self-driving car does
[00:10:50] count as a robot, not just
[00:10:53] >> where's the border of intelligence for
[00:10:54] you? I I think like it's probably some
[00:10:57] level of generalization, right? It can
[00:10:59] work in different environments. It can
[00:11:00] work on different tasks. It can work on
[00:11:01] different objects. Otherwise,
[00:11:04] >> self-driving car is okay. Yeah, I don't
[00:11:06] know. I didn't have that complex of a
[00:11:08] definition. I just had it as like
[00:11:09] something that will do
[00:11:11] >> certain pre-programmed types of labor
[00:11:13] for you. But maybe that's maybe I have a
[00:11:14] better definition. Let me look up what
[00:11:17] definition of robot is. a machine
[00:11:19] capable of carrying out a complex series
[00:11:21] of actions automatically,
[00:11:24] especially when programmable by a
[00:11:25] computer. But you know, all these things
[00:11:27] have chips in them now. Your dishwasher
[00:11:28] has a chip in it, right? Or the computer
[00:11:30] in it.
[00:11:30] >> Okay. Yes. But like uh I would argue
[00:11:33] that robotics has not been an
[00:11:35] interesting area of innovation without
[00:11:37] intelligence. And so that's the relevant
[00:11:39] set for maybe you and me and many people
[00:11:41] that are looking for something that
[00:11:43] changes quickly.
[00:11:44] >> Yeah, that's cool. I mean, I do think
[00:11:46] that um on the on the on the topic of
[00:11:49] robots, the biggest trend perhaps or one
[00:11:51] of the biggest trends of 2026 100% will
[00:11:54] be that self-driving will really begin
[00:11:56] to matter and that'll be both in terms
[00:11:57] of your own car, it'll be in terms of
[00:11:59] Whimo and Tesla caps. It's going to be I
[00:12:02] think one of the big things that's
[00:12:03] talked about next year. So, I think I
[00:12:05] think on the robotics team that's the
[00:12:06] big E.
[00:12:07] >> I think if you um look at all of the
[00:12:10] potential use cases for robots besides
[00:12:12] self-driving and say like self-driving
[00:12:15] >> I mean the Optimus team actually proves
[00:12:16] this like if you take if you take a
[00:12:18] model that is powering Tesla
[00:12:20] self-driving and you put it in Optimus
[00:12:22] it can do locomotion but it can't do
[00:12:24] many other things and you still have to
[00:12:25] do the hardware right like manipulation.
[00:12:27] And so I think that the advantages here
[00:12:30] are not as strong as you believe they
[00:12:31] are. And like startups, some set of
[00:12:33] startups,
[00:12:34] >> the scariest competition is the Chinese,
[00:12:36] but I I do think that there is
[00:12:37] opportunity here.
[00:12:38] >> Oh, I totally think there's opportunity
[00:12:40] for startups. And don't misinterpret me.
[00:12:42] I just think that it's not just the fact
[00:12:44] that you have a model or a base model.
[00:12:46] You have the expertise to build the
[00:12:47] model, but then you also have all the
[00:12:48] supply chain. And I think that's really
[00:12:50] important because a lot of the same
[00:12:52] sensors that you need to use are there.
[00:12:54] and you know how you think about
[00:12:55] actually procuring and scaling things is
[00:12:57] there you know there's there's good
[00:12:58] overlap actually in terms of some of the
[00:13:00] other skill sets that are needed that
[00:13:01] take a long time to build usually at a
[00:13:02] startup or that are a little bit painful
[00:13:04] to build and people do it it's fine it's
[00:13:06] not I mean did it and SpaceX did it and
[00:13:08] you know all these companies have done
[00:13:09] it it's extra stuff so that makes sense
[00:13:12] I I do think I do think some startups
[00:13:13] will succeed here I just trying to think
[00:13:15] through you know besides the startups
[00:13:18] who's going to be big and then also I
[00:13:19] think there are one or two like
[00:13:20] incumbent slots that will just default
[00:13:22] happen unless something very strange
[00:13:24] happens and you know one could have
[00:13:26] argued that should have happened in
[00:13:27] foundation models where Google should
[00:13:28] have had a default slot in the end it
[00:13:30] did right it got there and I think that
[00:13:33] was very predictable that the Google
[00:13:35] models will get good I think I even may
[00:13:37] have wrote a post about this like two
[00:13:38] three years ago that Google will be
[00:13:39] relevant right because they just had all
[00:13:42] the assets that were needed for them to
[00:13:44] be a really important foundation model
[00:13:46] company they obviously invented
[00:13:47] transformers but they had all the data
[00:13:48] they had all the capital they had TPUs
[00:13:49] and GPUs had like the best people for
[00:13:51] all sorts of things or some of the
[00:13:53] people. So, um, it felt inevitable and I
[00:13:56] think this feels the same to me. That
[00:13:57] doesn't mean it's right. Do you want to
[00:13:58] talk about IP as an M&A next year? What
[00:14:01] do you think will happen there? I think
[00:14:02] that's another big that's theme number
[00:14:04] four, five, I guess. You know, three was
[00:14:07] different types of models, four was
[00:14:09] robots and self-driving, and then five
[00:14:10] would be IPOs and M&A. What do you
[00:14:12] think? More IPOs, less IPOs, more M&A,
[00:14:15] less M&A, different types of M&A?
[00:14:17] >> It depends on whether or not the bottom
[00:14:19] of falls out of the AI market at some
[00:14:21] point, right? But I think regardless,
[00:14:23] >> what do you mean by the what do you mean
[00:14:24] the bottom falls out? Like what what
[00:14:26] what does that translate into?
[00:14:28] >> Uh I think people just get skittish
[00:14:30] about you you know the cycle here is
[00:14:32] like what are people scared of? They are
[00:14:34] concerned that demand isn't real. no
[00:14:37] demand isn't real um for AI to support
[00:14:40] the capex cycle that there is systemic
[00:14:44] risk from people passing the ball around
[00:14:47] in terms of who is actually responsible
[00:14:50] for the capex buildout and these credit
[00:14:52] agreements right or um you know pay on
[00:14:55] delivery contracts for data centers and
[00:14:57] for chips what else are they afraid of
[00:15:00] they're afraid of like the
[00:15:03] >> microlastics aka like too much
[00:15:05] concentration
[00:15:06] in Nvidia and a small number of other
[00:15:08] players. If you're like a big public
[00:15:10] markets investor, you're just like, you
[00:15:13] know, you
[00:15:13] >> silicon, it's too much silicon.
[00:15:15] >> It's too much silicon. You're damned if
[00:15:17] you do, you're damned if you don't. I
[00:15:19] was talking to a friend of mine who runs
[00:15:21] a large tech hedge fund
[00:15:23] >> and they're already like a foundation
[00:15:26] model investor in like multiple
[00:15:28] significant labs that may or may not go
[00:15:30] public in the next couple years. Yeah.
[00:15:32] And they're like, "Okay, well the
[00:15:33] question is, do you buy the IPO?" Their
[00:15:35] game theory on it was like, "Actually,
[00:15:37] no matter what I think about it, I have
[00:15:39] to do it because retail will want it
[00:15:42] >> because they like want to be part of the
[00:15:44] AI revolution." And then if you're a
[00:15:46] hedge fun, you get benchmarked on annual
[00:15:48] performance and because of the retail
[00:15:50] pop and some set of investors wanting to
[00:15:52] buy into it as a pure play where you're
[00:15:54] like, "Oh, I can't miss it like I missed
[00:15:56] Nvidia." Then you have to buy it. And so
[00:15:59] his view was like you buy the IPO
[00:16:02] regardless of your fundamental view of
[00:16:03] the company. And I was like, "Wow, this
[00:16:05] is not the investing job I know how to
[00:16:06] do."
[00:16:07] >> What do you think happens?
[00:16:08] >> I think there'll definitely be a lot
[00:16:09] more IPOs next year. Um, I think if one
[00:16:11] of the main AI companies goes out, it'll
[00:16:14] be probably do extremely well depending
[00:16:16] where they price. I mean, they obviously
[00:16:17] if they're overly aggressive, it won't,
[00:16:19] but in general, I think there's so much
[00:16:20] retail appetite to actually participate
[00:16:21] in AI besides Nvidia. Um, and then
[00:16:24] that'll just get a lot of other people
[00:16:26] to go public to just followers on it.
[00:16:28] So, I I do expect there'll be a lot of
[00:16:29] them. It's just one that even goes out.
[00:16:32] Uh, and then also it's a great way to
[00:16:33] raise huge amounts of money for some of
[00:16:35] these labs potentially. So, um, it'll be
[00:16:37] interesting to watch what happens there.
[00:16:38] Any other predictions for 26? Yeah, I I
[00:16:42] uh I think that I did not believe that
[00:16:45] we were going to see that many like
[00:16:48] unique consumer experiences
[00:16:52] >> besides like chat GPT. I think we are
[00:16:54] going to see like a slate of consumer
[00:16:57] hardware that mostly fails, but I'm
[00:16:59] still openminded to it. And then
[00:17:00] definitely actually like it remains to
[00:17:02] me see if any of these scales, but I am
[00:17:04] seeing magical experiences of like
[00:17:08] really different consumer agent software
[00:17:11] that I like I actually want and will
[00:17:13] use. And I I think people are barely
[00:17:16] beginning to
[00:17:17] >> well I these companies are in stealth
[00:17:19] right now, but I I do think that like
[00:17:21] there's going to be a lot more product
[00:17:22] people that experiment with this and
[00:17:24] model companies that experiment with
[00:17:26] this next year. Um and so I'm I'm pretty
[00:17:28] optimistic about that. Yeah, I agree
[00:17:30] with that 100%. And I think um the big
[00:17:32] question is what will end up being a
[00:17:33] breakout startup and it'll undoubtedly
[00:17:35] be some and then what will be a startup
[00:17:37] that will grow really fast and then
[00:17:38] it'll get cop copied by the main
[00:17:40] lab/google and then it just gets
[00:17:42] incorporated into the core product. And
[00:17:44] the the interesting thing is unless a
[00:17:45] company truly hits escape velocity and
[00:17:47] build a network effect or something else
[00:17:49] that's really defensible, usually
[00:17:51] incumbents can launch two three years
[00:17:52] later and catch up. And so if they have
[00:17:54] the distribution and they have the core
[00:17:56] product and they have but you know to
[00:17:58] your point I think it's very exciting
[00:17:59] and I've been waiting for this for a
[00:18:00] while. I think two years ago, three
[00:18:02] years ago, um this guy David Song who
[00:18:04] was on my team at the time ran a two
[00:18:08] quarter thing at Stanford where we had
[00:18:09] different game supply uh from the
[00:18:12] engineering programs there and it was
[00:18:14] like groups of people building consumer
[00:18:16] apps using AI because we said this wave
[00:18:19] of AI is so fascinating why didn't
[00:18:20] anybody building anything consumer so we
[00:18:22] basically just gave people free GPU to
[00:18:25] go and try stuff and there was no like
[00:18:28] obligation on their side to do anything
[00:18:30] with it you you know, in terms of us
[00:18:31] getting involved. It was just you go do
[00:18:33] cool stuff cuz this is such a good
[00:18:35] playground and it was really neat
[00:18:37] experiences that were being prototyped
[00:18:39] and then I was just shocked that nothing
[00:18:41] happened for a couple years in terms of
[00:18:44] you know really interesting consumer
[00:18:45] products. So I agree with you there's so
[00:18:46] much room for that and I always wonder
[00:18:48] is it because there's a different
[00:18:49] generation of founders who don't want to
[00:18:51] work on consumer or who've forgotten how
[00:18:53] because you know the big consumer
[00:18:55] companies have kind of aged out. Is it
[00:18:58] the incumbents are just too scary? Is it
[00:19:00] like what why is there so little
[00:19:01] innovation actually on the consumer side
[00:19:03] of AI? I still don't quite understand
[00:19:05] what the issue is.
[00:19:07] >> I Okay, let's let's like list the
[00:19:09] reasons. I do think that the incumbents
[00:19:11] are pretty scary. Um and anybody who was
[00:19:14] around for the last generation of
[00:19:15] interesting consumer ideas saw actually
[00:19:18] the ingestion of those ideas into the
[00:19:20] existing platform as you put out.
[00:19:22] >> Yeah.
[00:19:22] >> So there's that. I also think like the
[00:19:25] first instinct that that I've seen from
[00:19:28] companies uh from founders working on
[00:19:31] like new consumer experiences is
[00:19:33] essentially building like better
[00:19:34] versions of like last generation
[00:19:36] experiences with this generation
[00:19:38] technology and it ends up like not being
[00:19:40] that interesting. And so I actually
[00:19:41] think you have to be like either quite
[00:19:43] close to research or pretty creatively
[00:19:46] ambitious to build like something very
[00:19:48] different that has any chance. And so
[00:19:50] [clears throat] I think I think like
[00:19:52] there's just not that many people who
[00:19:53] have had that experience set or that
[00:19:55] creativity and now we're going to see
[00:19:57] it.
[00:19:58] >> Yeah, I think it's pretty exciting. The
[00:19:59] other thing is um I was talking to a
[00:20:02] really well-known consumer founder who's
[00:20:04] running you know a giant public company
[00:20:07] and his view is that perhaps in the
[00:20:09] entire world there's a few hundred great
[00:20:12] product people for consumer at least in
[00:20:15] terms of who are actually working on it.
[00:20:16] Obviously there's enormous human
[00:20:17] potential and people who aren't working
[00:20:19] in consumer products could and you know
[00:20:21] but of the people working consumer
[00:20:22] products he thinks at most there's a few
[00:20:23] hundred people who are exceptional who
[00:20:25] could actually come up with and launch
[00:20:27] their own product that would be
[00:20:28] interesting or good and so you could
[00:20:30] also just say say that maybe there's
[00:20:32] just a limitation on how many of these
[00:20:33] things can exist just given human
[00:20:35] potential within the set of people who
[00:20:37] are already doing it which I think is
[00:20:38] kind of an interesting argument I don't
[00:20:40] know if I agree with it but I thought it
[00:20:41] was an interesting argument that he made
[00:20:42] >> I would limit myself to that number if
[00:20:45] it it's also the set people who like
[00:20:48] have the context of like what is
[00:20:50] possible now.
[00:20:52] >> If you've got great consumer product
[00:20:53] instinct, but you're like work you're
[00:20:55] like grinding away on the like 50th
[00:20:58] iteration of an existing product like
[00:21:02] >> Yeah. Yeah. You're working on the the
[00:21:04] the little sub button in Gmail or
[00:21:05] whatever instead of actually going off
[00:21:06] and doing this 100%.
[00:21:08] >> Yeah.
[00:21:08] >> Cool. Anything else we should talk about
[00:21:10] or any other big predictions for 26? I
[00:21:12] feel like a very big um emergent thing
[00:21:15] that happened this year was the
[00:21:17] surprising funding of like Neolabs like
[00:21:21] three through eight. What do you think
[00:21:22] of that? What do you think about
[00:21:23] alternative architectures? Like do you
[00:21:27] have any point of view on um all of the
[00:21:29] effort around like getting reinforcement
[00:21:32] learning to be more general continual
[00:21:34] learning? Uh some of the research
[00:21:35] directions
[00:21:36] >> you know I think there's enormous
[00:21:37] amounts of really interesting research
[00:21:39] being done. So I, you know, there's a
[00:21:41] lot of juice to be squeezed out of these
[00:21:42] models still in different ways and I
[00:21:45] think that's really exciting. Well,
[00:21:46] ultimately these things become capital
[00:21:48] gains for certain types of approaches or
[00:21:50] models because we know scale really
[00:21:52] matters which means that eventually you
[00:21:53] have to have collapse into a handful of
[00:21:55] players because capital will aggregate
[00:21:56] to things that are working the most.
[00:21:58] They're generating revenue and so then
[00:21:59] the question is what are those things?
[00:22:01] At what point do things just get kind of
[00:22:03] locked in from a usage perspective for
[00:22:05] whatever reason? And there's all sorts
[00:22:06] of ways you can imagine this being built
[00:22:07] over time against some of the models. So
[00:22:10] I think it's interesting. I think it's
[00:22:12] exciting. I think we'll see how it plays
[00:22:13] out.
[00:22:14] >> I think to articulate what like the the
[00:22:17] arguments could be for, you know, new
[00:22:20] research directions is like Ilia, you
[00:22:22] know, did this interview [clears throat]
[00:22:24] recently where he describes it as the
[00:22:25] age of research. And to to paraphrase,
[00:22:28] he like basically says that yes, I
[00:22:31] believe in scaling of course, but you
[00:22:33] know, there's there's some
[00:22:36] floor of compute that is not infinite
[00:22:39] where we can test ideas at scale. And
[00:22:42] then if we have [clears throat] let's
[00:22:43] say secret ideas around like how to get
[00:22:47] to more rapid or more compute efficient
[00:22:50] improvement then it actually isn't just
[00:22:52] a straight resource battle which like
[00:22:54] the rat race does feel a little bit like
[00:22:56] today. Um, I think the other argument
[00:23:00] you you could take is actually like
[00:23:03] multiple architectures and people have
[00:23:04] done some research on this, but multiple
[00:23:05] architectures are really relevant at big
[00:23:08] domains of of um usefulness. They just
[00:23:13] haven't been scaled, right? And like
[00:23:15] there's enough capital out there to test
[00:23:17] them, be they like diffusion or um SSMs
[00:23:20] or whatever. And that's going to happen
[00:23:21] this next year. And then I think there's
[00:23:23] like a like a resource focus argument,
[00:23:25] right? If Ilia is describing that some
[00:23:28] set of labs they have an enormous amount
[00:23:29] of compute but they have to spend a lot
[00:23:31] of that compute on inference today then
[00:23:33] how much do you spend on your particular
[00:23:35] research direction uh be it
[00:23:39] self-improvement or post- training or
[00:23:41] emotional intelligence or very large
[00:23:43] scale out agent stuff.
[00:23:45] >> Yeah, it depends on what you're doing
[00:23:46] because the inference is what ends up
[00:23:47] then uh raising you money to pay for
[00:23:50] everything else because you're
[00:23:51] generating revenue. So I think uh sure
[00:23:54] that it's effectively your way to
[00:23:56] bootstrap into more and more scales. So,
[00:23:58] I always thought perhaps incorrectly. I
[00:24:00] I actually probably think it's
[00:24:01] incorrect, but I always thought that
[00:24:03] eventually you end up with evolutionary
[00:24:05] systems is really how you build AI
[00:24:09] because and maybe I'm overextulating up
[00:24:11] a biology where you know effectively
[00:24:12] your brain has a series of modules that
[00:24:14] have different functions or tasks,
[00:24:15] right? You have a visual system that's
[00:24:19] um you know highly sort of pre-wired to
[00:24:22] deal with vision really effectively. You
[00:24:24] have uh different areas of high pier
[00:24:26] thought and learning. You have memory.
[00:24:28] You have uh mirror neurons that are
[00:24:30] involved with empathy, right? Your brain
[00:24:32] is actually very um specialized in some
[00:24:34] ways. Although obviously there's people
[00:24:35] who are born with literally like half a
[00:24:36] brain hemisphere and the brain rewires
[00:24:39] and sort of covers all the
[00:24:40] functionality. But um there's a few
[00:24:42] famous cases like that. Uh but you know
[00:24:46] fundamentally um you have a lot of stuff
[00:24:49] that evolves into very specialized
[00:24:50] tasks. It's almost like ae or something,
[00:24:52] you know. And the question is the degree
[00:24:56] to which you recapitulate that as you're
[00:24:57] doing further development of AI. And
[00:25:00] when do you start just spawning off a
[00:25:02] bunch of instances of something and just
[00:25:04] have some utility function evolving
[00:25:06] against that you then have some
[00:25:08] selection and recombining and all the
[00:25:09] other stuff that you kind of do to to
[00:25:11] try and make some of that work versus
[00:25:13] how much of it is a more analytical
[00:25:14] approach or a more experimental and
[00:25:16] iterative approach or you know so it's
[00:25:19] or in a directed way. And so I think
[00:25:21] it's really interesting to ask cuz if
[00:25:22] you look again at biology as a as a
[00:25:25] potential precedent although maybe a
[00:25:27] very bad one. You look at protein design
[00:25:30] and for a long time there are these like
[00:25:33] super analytically designed proteins and
[00:25:34] then they came up with all these systems
[00:25:36] of this you know like phase display
[00:25:39] and like mutagenic scans and all sorts
[00:25:41] of things that give you dramatically
[00:25:42] better results than if you just sat and
[00:25:43] thought about it. And now of course we
[00:25:46] kind of solved it with AI where you have
[00:25:48] um all these 3D structural prediction
[00:25:50] that are actually very good right that
[00:25:53] that was um alpha fold and a few other
[00:25:55] things that really were breakthroughs
[00:25:56] there. So it feels like in the context
[00:25:59] of AI maybe eventually we end up there
[00:26:01] as well right where you just involve
[00:26:02] these systems and then that may be a
[00:26:05] very different type of approach and
[00:26:07] training and you know that that that may
[00:26:09] be where I think things really have a
[00:26:10] interesting break and that's one of the
[00:26:12] reasons arguably people are so focused
[00:26:14] on code because code is arguably a
[00:26:15] bootstrap into moving faster on
[00:26:17] development of AGI but I think it's kind
[00:26:20] of code plus self-evolution is really
[00:26:22] the the potential really interesting
[00:26:24] approach to it to to get some really
[00:26:26] fast lift off but Maybe not, right?
[00:26:27] We'll see.
[00:26:28] >> What is um the one prediction you have
[00:26:32] for 26 that has nothing to do with AI?
[00:26:35] >> Do you think about anything else, Sarah?
[00:26:36] [laughter]
[00:26:38] >> I do.
[00:26:39] >> I'm joking.
[00:26:40] >> Really?
[00:26:42] >> I mean, the other thing, by the way, one
[00:26:44] other prediction that does have to do
[00:26:45] with AI is I do think um defense will
[00:26:49] accelerate in terms of startups and
[00:26:50] defense tech and the shift to autonomous
[00:26:53] or not autonomous but to drone based
[00:26:55] systems in general. a massive reworking
[00:26:57] of how you think about war and defense
[00:26:59] and I think that's going to be a shoot
[00:27:00] shift that we'll see go even faster this
[00:27:02] coming year I think this is accelerating
[00:27:04] in part to you know how the Trump
[00:27:06] administration has been approaching it
[00:27:07] and the secretary of war and everybody
[00:27:08] there have been thinking about it but I
[00:27:10] think in part just you have enough
[00:27:11] density now of startups doing
[00:27:12] interesting things so I think that's the
[00:27:14] other thing that's like a huge shift
[00:27:15] that you know it's a hype cycle right
[00:27:17] now and I actually think again it's a
[00:27:19] little bit under thought about because
[00:27:20] it's it's going to be so big um outside
[00:27:23] of AI I mean I think there's obvious
[00:27:24] really interesting things happening in
[00:27:25] space SpaceX and Starlink and I think
[00:27:28] about communications and telefan that's
[00:27:30] a big shift. There's really interesting
[00:27:32] things in my opinion happening in energy
[00:27:33] and mining and you know I I think
[00:27:35] there's a lot going on in the world.
[00:27:37] >> I agree on defense
[00:27:40] with some like concern that you know we
[00:27:43] have to wait for budget to actually
[00:27:45] shift from contracts to primes to some
[00:27:47] of these new companies at scale. But the
[00:27:50] demand like the need to be competitive
[00:27:52] in a world that's increasingly
[00:27:54] autonomydriven
[00:27:56] um is like so obvious right and I think
[00:27:59] you know hype cycles and booms are good
[00:28:01] in that they bring a lot of people to
[00:28:04] the table you know capital
[00:28:06] >> founders people who want to work in the
[00:28:08] industry um and so you can make a lot of
[00:28:10] progress in a quick amount of time even
[00:28:12] if a lot of companies die
[00:28:14] >> and there's there's um more enthusiasm a
[00:28:17] very short period of time so I agree
[00:28:19] with that. And I also don't think that's
[00:28:21] necessarily bad, right? I
[00:28:23] >> What's your high prediction?
[00:28:25] >> I think that like I'm not the only one,
[00:28:27] but I think that the like
[00:28:28] [clears throat] GLP1 thing is just
[00:28:31] >> despite all of the enthusiasm, like
[00:28:34] still underrated for how much impact it
[00:28:36] is having, right? And so I think that
[00:28:39] the continual adoption of these is like
[00:28:42] inexurable. I actually think it creates
[00:28:44] a path that is interesting for like
[00:28:48] other peptide and hormone therapies.
[00:28:51] >> I think the fact that it has been so
[00:28:53] effective has like lots of second order
[00:28:55] effects both from people way like just
[00:28:58] being a lot less overweight like
[00:29:01] directly and the willingness to look at
[00:29:04] other engineered peptides or like I
[00:29:07] think it like everybody understands now
[00:29:09] that like
[00:29:11] >> delivery matters. there are these really
[00:29:13] incredible medicines and I think that
[00:29:15] the impact of that is going to like fuel
[00:29:17] much more investment in um anything that
[00:29:20] looks like that type of opportunity and
[00:29:21] so I think that's exciting.
[00:29:23] Yeah, I actually think um one thing that
[00:29:25] you mentioned is really interesting
[00:29:27] where if you look at the sort of
[00:29:28] biohacking community, there's a lot of
[00:29:30] peptide use now of different you know
[00:29:32] different peptides that will do
[00:29:33] different things in terms of you know
[00:29:36] somebody will have some chronic corporal
[00:29:37] cheerle thing and they'll fly to Dubai
[00:29:38] to get you know peptides injected or
[00:29:40] whatever and usually those are sort of
[00:29:43] early indicators of potential larger
[00:29:44] scale adoption society
[00:29:46] >> and so I think that's a really
[00:29:48] interesting trend right now in general
[00:29:49] like this whole like um world of
[00:29:51] peptides and their uses. and is there a
[00:29:53] hymns of peptides like what's the what's
[00:29:56] coming there so I think that's super
[00:29:57] interesting you know
[00:29:58] >> I also think like the biohacking
[00:30:00] community as you said it like the set of
[00:30:03] people who were really really early off
[00:30:06] label GLP-1 adopters um interested in
[00:30:11] longevity neurom modulation with
[00:30:14] ultrasound um stem cell injection for
[00:30:17] example like that has been like a fringe
[00:30:19] small community
[00:30:20] >> and I think that like I think it's going
[00:30:23] to get less French.
[00:30:24] >> Uh and a lot of these things
[00:30:25] traditionally 10 years ago came out of
[00:30:27] the bodybuilding community, right? The
[00:30:28] bodybuilding community was like creatine
[00:30:30] and all these things that are more
[00:30:31] broadly used now, but also other other
[00:30:33] things for sleep aids or other, you
[00:30:35] know, magnesium and all this stuff.
[00:30:37] >> And to round out this year-end episode,
[00:30:39] we've asked some of our friends for
[00:30:41] their predictions for 2026. I'm so
[00:30:43] curious. My prediction for next year is
[00:30:47] that uh the reasoning
[00:30:51] uh systems are going to translate
[00:30:54] directly uh to AIS that are much much
[00:30:59] more versatile, much much more robust
[00:31:01] and reasoning is going to impact is
[00:31:04] going to revolutionize not just not just
[00:31:06] language models but reasoning is going
[00:31:08] to impact every single industry from
[00:31:11] biology to uh self-driving cars to
[00:31:15] robotics. And so reasoning, I think, is
[00:31:18] is the big huge breakthrough that that
[00:31:22] um is going to transform a lot of
[00:31:24] different applications and industries.
[00:31:26] In 2026, AI will stop being a reactive
[00:31:29] tool that waits for us to prompt it.
[00:31:32] Instead, it will become very proactive
[00:31:35] and get deeply integrated in our work
[00:31:37] life. It'll go where we go, hear what we
[00:31:41] hear, know what tasks we need to work
[00:31:45] on, and in fact, most of the times
[00:31:48] complete those for us before we even ask
[00:31:50] it to do so. It'll be our coach that
[00:31:53] helps us improve our skills. It'll be
[00:31:56] our manager who helps us prioritize our
[00:31:58] work and manage our time. In short, it's
[00:32:01] going to be the best work companion we
[00:32:03] could wish for. I think the main AI
[00:32:05] prediction that I have for next year is
[00:32:07] I think context is just going to be the
[00:32:09] most important part of every single
[00:32:10] product. And honestly, like one of the
[00:32:12] best experiences I've had with it so far
[00:32:14] is just memory and chatbt. Like I think
[00:32:17] that there are going to be a lot more
[00:32:19] features that basically
[00:32:22] their goal is to extract the user intent
[00:32:24] and make the onus less on the user to
[00:32:27] basically give all of the models or the
[00:32:28] system or the product more and more
[00:32:30] context. So in other words, how do you
[00:32:33] put the onus on the product to actually
[00:32:35] extract that from the user instead of
[00:32:38] the user having to do all of the work to
[00:32:40] do this up front?
[00:32:41] >> My prediction for 2026 is there will be
[00:32:44] a whole new suite of product experiences
[00:32:46] that run on much faster inference.
[00:32:50] >> My prediction for 2026 is that we'll
[00:32:52] finally stop copy pasting stuff into
[00:32:54] chat boxes. Instead, I think we're going
[00:32:56] to have applications that have better
[00:32:59] use of screen sharing and context
[00:33:00] management across the sources that
[00:33:02] matter the most.
[00:33:03] >> One prediction for 2026, there's so much
[00:33:06] talk of agents right now and there has
[00:33:08] been for a while, but no one has truly
[00:33:10] created a mass scale consumer agentic
[00:33:13] AI. I think the models are there today
[00:33:15] for this to be possible. And in 2026, we
[00:33:17] will see the group that figures out the
[00:33:19] right interface and system and product
[00:33:21] that creates as big a step function and
[00:33:23] overall experience as chat did when it
[00:33:24] first came out. And I think this area is
[00:33:26] not nearly as seated to the labs as
[00:33:28] people assume. It really is anyone's
[00:33:30] ball game. Hello, Aaron here. First of
[00:33:32] all, I get quite awkward around doing
[00:33:34] selfie videos. This is my ninth take of
[00:33:37] this video. Um so I hope it goes okay
[00:33:39] but uh 2026 prediction would be that uh
[00:33:43] this is going to be certainly the
[00:33:44] continued year number two of uh AI
[00:33:47] agents but in particular AI agents in
[00:33:50] the enterprise in either deep vertical
[00:33:52] or domain specific areas. Um I think
[00:33:55] this is going to be the main way that we
[00:33:57] actually take all of the progress that
[00:33:59] we're seeing in AI models and actually
[00:34:01] deliver them into the enterprise. You
[00:34:03] have to be able to tie to the workflow
[00:34:05] of the organization. You have to be able
[00:34:06] to get access to the data that they
[00:34:08] have. You have to have the right context
[00:34:10] engineering to make the agents actually
[00:34:11] work. And then you have to do the change
[00:34:13] management that makes the agents
[00:34:14] effective. So this is going to be a year
[00:34:16] where we start to see this pattern
[00:34:17] emerge more and more. Uh which equally
[00:34:19] means that we need to ensure that we
[00:34:21] have a lot more happening on agent
[00:34:23] harnesses. So shout out to Aorvosu and
[00:34:26] Dex for that answer. Uh but it's
[00:34:28] definitely going to be the year of age
[00:34:29] and harness and seeing how do you start
[00:34:31] to get you know an order of magnitude
[00:34:33] improvement on the model's capabilities
[00:34:36] by having all the right scaffolding
[00:34:38] around the model. Uh and then finally it
[00:34:40] will be the year of uh economically
[00:34:42] useful evals. Um so really starting to
[00:34:45] figure out how these models end up doing
[00:34:47] a lot more knowledge worker tasks in the
[00:34:49] economy. Um and that's going to uh we're
[00:34:51] going to see a lot more of that in 2026.
[00:34:53] We saw some previews of that this year
[00:34:54] with Apex and GDP Val uh and a handful
[00:34:57] of others. We're going to see way more
[00:34:59] of that. So, those are the predictions
[00:35:01] and we'll see you uh in 2026.
[00:35:04] >> I think 2026 is going to be a very
[00:35:07] interesting year for American open
[00:35:09] models. Over the last year, the frontier
[00:35:13] of open intelligence shifted from
[00:35:15] America to China, starting with the
[00:35:17] release of Deep Seek at the end of 2024.
[00:35:20] and American institutions were slow to
[00:35:23] notice this erosion of American
[00:35:25] leadership in open intelligence but uh I
[00:35:29] think they've noticed in a big way over
[00:35:31] the last half year both from the
[00:35:33] government level from the enterprise
[00:35:36] level and there are some really
[00:35:37] interesting uh neolabs starting to come
[00:35:39] out with open intelligence as their
[00:35:42] directive and there are a few of these
[00:35:43] not just reflection and these companies
[00:35:47] are starting to produce some very
[00:35:49] interesting
[00:35:50] small open models and next year I think
[00:35:53] we'll see the US regaining leadership at
[00:35:56] the open weight frontier at the largest
[00:35:58] scale and I'm really excited to see
[00:36:00] that. Hey folks, my prediction for 2026
[00:36:04] is that I think we will see AI become
[00:36:07] much more politicized. I think we'll see
[00:36:09] it become a major point of discussion
[00:36:12] for the 2026 midterm elections and some
[00:36:15] people will come out strongly against
[00:36:17] it. Some people will come out. It's
[00:36:18] probably supportive of it. And um I'm
[00:36:21] not sure which side's going to win out.
[00:36:22] >> 2025 has marked an incredible year in AI
[00:36:26] drug discovery. In the past year alone,
[00:36:28] we've gone from being able to design
[00:36:30] simple molecules on the computer to
[00:36:32] designing simple antibodies and now most
[00:36:35] recently fulllength antibodies with
[00:36:37] drug-like properties zero shot on the
[00:36:39] computer. If 2025 has been the year of
[00:36:42] research in AI drug discovery, 2026 will
[00:36:45] be the year of deployment. The models
[00:36:48] have finally entered an era where
[00:36:50] they're becoming really useful for drug
[00:36:51] discovery. Not only do they make things
[00:36:54] faster, but they're also allowing us to
[00:36:56] go after really challenging targets
[00:36:58] which have been traditionally really
[00:37:00] difficult to do with traditional
[00:37:01] techniques. I'm really excited to see
[00:37:03] what comes next because the models show
[00:37:05] no signs of slowing down. Okay, my
[00:37:08] prediction for 2026 is it will be the
[00:37:10] year that YOLO dies. we will begin
[00:37:12] transforming ourselves from a you only
[00:37:14] live once to don't die. I think right
[00:37:17] now we're kind of a suicidal species. We
[00:37:19] do very primitive things. We poison
[00:37:21] ourselves with what we eat. We design
[00:37:23] our lives so that we slowly kill
[00:37:25] ourselves. Companies make profits by
[00:37:27] making us addicted and miserable. We
[00:37:29] destroy the only home we have. And
[00:37:31] somehow we celebrate these things as
[00:37:33] virtue. I think it's all backwards. And
[00:37:36] I think one day we'll look back and
[00:37:38] we'll be pretty astonished that we
[00:37:40] behaved like this. Um I think the simp
[00:37:42] the shift coming is going to be simple
[00:37:44] and radical that we say yes to life and
[00:37:47] no to death. It's simple but I think it
[00:37:50] could be in response to AI's progress.
[00:37:52] And we do this defiantly as a form of
[00:37:55] unification. Um I think it does require
[00:37:57] a lot of courage for us though to say we
[00:37:59] recognize how sacred our existence is.
[00:38:02] We don't want to throw it away and we
[00:38:04] want to defend it with every bit of
[00:38:06] courage and strength we have uh because
[00:38:08] it is so precious. I think it's going to
[00:38:10] be the year we end yolo and the
[00:38:12] beginning of don't die.
[00:38:14] >> The most striking thing about next year
[00:38:15] is that the other forms of knowledge
[00:38:17] work going to experience what software
[00:38:18] engineers are feeling right now where
[00:38:20] they went from typing you know most of
[00:38:22] their lines of code at the beginning of
[00:38:23] the year to typing barely any of them at
[00:38:25] the end of the year. I think of this as
[00:38:26] the claude code experience but for all
[00:38:28] forms of knowledge work. I also think
[00:38:30] that probably continual learning gets
[00:38:31] sold in a satisfying way, that we see
[00:38:33] the first test deployments of home
[00:38:35] robots, and the software engineering
[00:38:36] itself goes utterly wild next year.
[00:38:39] >> My prediction for 2026 is that it's the
[00:38:42] year where everyone's perceptions are
[00:38:43] flipped. Currently, everyone believes
[00:38:45] that you can only use Nvidia outside of
[00:38:47] Google, and that will be obvious that
[00:38:50] that's not the case. Currently, about a
[00:38:52] third of Americans hate AI and think
[00:38:54] it's really bad. That number will
[00:38:56] increase. Currently, most Americans
[00:38:59] think AI is not useful. That will flip
[00:39:02] as well. And so, everyone's priors will
[00:39:05] be flipped. That's because the
[00:39:07] transformative use of AI will be so
[00:39:11] prevalent. The the obvious utility of it
[00:39:13] will be so high that there is no way for
[00:39:16] anyone's priors. You know, cognitive
[00:39:18] dissonance will be wiped away.
[00:39:20] >> Hey, I'm Ben Spectre.
[00:39:21] >> I'm Ash Spectre.
[00:39:23] >> And our prediction is that 2026 is the
[00:39:24] year of energy efficient AI. Data center
[00:39:27] buildings are primarily constrained by
[00:39:28] energy, power availability, great
[00:39:30] interconnects, high voltage equipment,
[00:39:31] things like that. Which is why XAI's
[00:39:33] Colossus was initially powered by
[00:39:35] on-site gas trends. The thing is the
[00:39:37] demand for computing to grow. Labs,
[00:39:39] Neolabs like us and like Kurser have a
[00:39:42] pretty remarkably insatable demand for
[00:39:44] both training and compute. And this
[00:39:45] demand is currently on stripping our
[00:39:46] ability to push lots onto the grid. This
[00:39:49] means that in 2026, it will be really
[00:39:50] important to squeeze every available bit
[00:39:52] of tons out of every wallet. That said,
[00:39:55] in the long term, chips probably matter
[00:39:56] more than power because chips depreciate
[00:39:58] much more quickly than the underlying
[00:40:00] power infrastructure.
[00:40:01] >> So, for example, with data center power
[00:40:02] supplies at 10 per kilowatt hour, the
[00:40:04] chips cost action order imaging more
[00:40:06] than the power than a 5-year
[00:40:08] depreciation cycle.
[00:40:09] >> So, in 2026, we think intelligence per
[00:40:12] watch is really important to squeeze as
[00:40:13] much intelligence you can out of every
[00:40:15] unit of energy. But in the long term, we
[00:40:17] think it's the chips that matter more.
[00:40:18] >> Happy holidays.
[00:40:19] >> Happy New Year.
[00:40:21] >> Thanks for the year. Happy 2026.
[00:40:23] >> Happy 2026, listeners. Thank you.
[00:40:28] >> Find us on Twitter [music] at no prior
[00:40:30] pod. Subscribe to our YouTube channel if
[00:40:32] you want to see our faces. Follow the
[00:40:34] show on Apple Podcasts, Spotify, or
[00:40:37] wherever you listen. That way, you get a
[00:40:38] new [music] episode every week. And sign
[00:40:40] up for emails or find transcripts for
[00:40:42] every episode at no-bers.com. [music]
