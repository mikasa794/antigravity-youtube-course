[00:00:00] We're just living in a time where AI is
[00:00:03] transforming everything. It's
[00:00:05] transforming [music] how we work within
[00:00:07] disciplines like science or climate
[00:00:09] change or medicine or all forms of
[00:00:12] technology.
[00:00:14] It's driving economies worldwide. And in
[00:00:18] some cases, it's leading to outcomes
[00:00:20] that perhaps [music] weren't as intended
[00:00:22] and not as beneficial as we would hope
[00:00:25] them to be. In this really powerful
[00:00:27] disruptive [music] technology, there's a
[00:00:29] lot of good and opportunity, but there's
[00:00:31] potential for downside that we have to
[00:00:33] just be really mindful of. In my [music]
[00:00:36] research, I know because I develop these
[00:00:38] systems. I develop these systems to help
[00:00:41] people learn new things. I help I build
[00:00:43] systems that help [music] persuade
[00:00:44] people um to be a to to to take
[00:00:47] healthier actions. So these are
[00:00:49] technologies that are influencing the
[00:00:51] way we learn, our decisions, our [music]
[00:00:53] opinions, our behaviors. It's our
[00:00:56] decisions. It's what's causing it to be
[00:00:58] applied in the way that it is. [music]
[00:01:00] Right? So having people just understand
[00:01:03] what AI is, that it is a tool for
[00:01:06] empowerment, it also has the risk of
[00:01:10] exacerbating [music]
[00:01:10] inequality if we're not careful. Right?
[00:01:12] So it's a change agent in a way that
[00:01:15] people just need to be much more savvy
[00:01:18] and cognizant about [music] so they can
[00:01:20] make intelligent informed decisions.
[00:01:25] [music]
[00:01:28] We created
[00:01:30] which is an MITwide initiative that
[00:01:32] stands for responsible AI for social
[00:01:34] empowerment and education. We're
[00:01:37] creating these innovative curriculum
[00:01:40] that introduce not only AI concepts and
[00:01:43] technologies but responsible design
[00:01:46] practices as well as societal
[00:01:48] implications of these technologies where
[00:01:50] the students are placed as the designer
[00:01:52] of these systems in our approach and we
[00:01:54] educate them [music] in these methods.
[00:01:56] They build things with it. They design
[00:01:58] things in groups. How do you make
[00:02:01] learning experiences more hightouch,
[00:02:04] more engaging, more emotionally
[00:02:05] engaging? So being able to track the
[00:02:07] learner's emotional state, their
[00:02:09] attentional state, [music] adapting the
[00:02:11] experience and the content accordingly.
[00:02:14] >> [music]
[00:02:20] [music]
